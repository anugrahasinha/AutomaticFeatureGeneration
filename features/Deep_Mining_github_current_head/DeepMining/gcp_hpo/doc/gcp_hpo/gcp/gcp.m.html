<!doctype html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />

    <title>gcp_hpo.gcp.gcp API documentation</title>
    <meta name="description" content="" />

  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300' rel='stylesheet' type='text/css'>
  
  <style type="text/css">
  
* {
  box-sizing: border-box;
}
/*! normalize.css v1.1.1 | MIT License | git.io/normalize */

/* ==========================================================================
   HTML5 display definitions
   ========================================================================== */

/**
 * Correct `block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
nav,
section,
summary {
    display: block;
}

/**
 * Correct `inline-block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

audio,
canvas,
video {
    display: inline-block;
    *display: inline;
    *zoom: 1;
}

/**
 * Prevent modern browsers from displaying `audio` without controls.
 * Remove excess height in iOS 5 devices.
 */

audio:not([controls]) {
    display: none;
    height: 0;
}

/**
 * Address styling not present in IE 7/8/9, Firefox 3, and Safari 4.
 * Known issue: no IE 6 support.
 */

[hidden] {
    display: none;
}

/* ==========================================================================
   Base
   ========================================================================== */

/**
 * 1. Prevent system color scheme's background color being used in Firefox, IE,
 *    and Opera.
 * 2. Prevent system color scheme's text color being used in Firefox, IE, and
 *    Opera.
 * 3. Correct text resizing oddly in IE 6/7 when body `font-size` is set using
 *    `em` units.
 * 4. Prevent iOS text size adjust after orientation change, without disabling
 *    user zoom.
 */

html {
    background: #fff; /* 1 */
    color: #000; /* 2 */
    font-size: 100%; /* 3 */
    -webkit-text-size-adjust: 100%; /* 4 */
    -ms-text-size-adjust: 100%; /* 4 */
}

/**
 * Address `font-family` inconsistency between `textarea` and other form
 * elements.
 */

html,
button,
input,
select,
textarea {
    font-family: sans-serif;
}

/**
 * Address margins handled incorrectly in IE 6/7.
 */

body {
    margin: 0;
}

/* ==========================================================================
   Links
   ========================================================================== */

/**
 * Address `outline` inconsistency between Chrome and other browsers.
 */

a:focus {
    outline: thin dotted;
}

/**
 * Improve readability when focused and also mouse hovered in all browsers.
 */

a:active,
a:hover {
    outline: 0;
}

/* ==========================================================================
   Typography
   ========================================================================== */

/**
 * Address font sizes and margins set differently in IE 6/7.
 * Address font sizes within `section` and `article` in Firefox 4+, Safari 5,
 * and Chrome.
 */

h1 {
    font-size: 2em;
    margin: 0.67em 0;
}

h2 {
    font-size: 1.5em;
    margin: 0.83em 0;
}

h3 {
    font-size: 1.17em;
    margin: 1em 0;
}

h4 {
    font-size: 1em;
    margin: 1.33em 0;
}

h5 {
    font-size: 0.83em;
    margin: 1.67em 0;
}

h6 {
    font-size: 0.67em;
    margin: 2.33em 0;
}

/**
 * Address styling not present in IE 7/8/9, Safari 5, and Chrome.
 */

abbr[title] {
    border-bottom: 1px dotted;
}

/**
 * Address style set to `bolder` in Firefox 3+, Safari 4/5, and Chrome.
 */

b,
strong {
    font-weight: bold;
}

blockquote {
    margin: 1em 40px;
}

/**
 * Address styling not present in Safari 5 and Chrome.
 */

dfn {
    font-style: italic;
}

/**
 * Address differences between Firefox and other browsers.
 * Known issue: no IE 6/7 normalization.
 */

hr {
    -moz-box-sizing: content-box;
    box-sizing: content-box;
    height: 0;
}

/**
 * Address styling not present in IE 6/7/8/9.
 */

mark {
    background: #ff0;
    color: #000;
}

/**
 * Address margins set differently in IE 6/7.
 */

p,
pre {
    margin: 1em 0;
}

/**
 * Correct font family set oddly in IE 6, Safari 4/5, and Chrome.
 */

code,
kbd,
pre,
samp {
    font-family: monospace, serif;
    _font-family: 'courier new', monospace;
    font-size: 1em;
}

/**
 * Improve readability of pre-formatted text in all browsers.
 */

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}

/**
 * Address CSS quotes not supported in IE 6/7.
 */

q {
    quotes: none;
}

/**
 * Address `quotes` property not supported in Safari 4.
 */

q:before,
q:after {
    content: '';
    content: none;
}

/**
 * Address inconsistent and variable font size in all browsers.
 */

small {
    font-size: 80%;
}

/**
 * Prevent `sub` and `sup` affecting `line-height` in all browsers.
 */

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

/* ==========================================================================
   Lists
   ========================================================================== */

/**
 * Address margins set differently in IE 6/7.
 */

dl,
menu,
ol,
ul {
    margin: 1em 0;
}

dd {
    margin: 0 0 0 40px;
}

/**
 * Address paddings set differently in IE 6/7.
 */

menu,
ol,
ul {
    padding: 0 0 0 40px;
}

/**
 * Correct list images handled incorrectly in IE 7.
 */

nav ul,
nav ol {
    list-style: none;
    list-style-image: none;
}

/* ==========================================================================
   Embedded content
   ========================================================================== */

/**
 * 1. Remove border when inside `a` element in IE 6/7/8/9 and Firefox 3.
 * 2. Improve image quality when scaled in IE 7.
 */

img {
    border: 0; /* 1 */
    -ms-interpolation-mode: bicubic; /* 2 */
}

/**
 * Correct overflow displayed oddly in IE 9.
 */

svg:not(:root) {
    overflow: hidden;
}

/* ==========================================================================
   Figures
   ========================================================================== */

/**
 * Address margin not present in IE 6/7/8/9, Safari 5, and Opera 11.
 */

figure {
    margin: 0;
}

/* ==========================================================================
   Forms
   ========================================================================== */

/**
 * Correct margin displayed oddly in IE 6/7.
 */

form {
    margin: 0;
}

/**
 * Define consistent border, margin, and padding.
 */

fieldset {
    border: 1px solid #c0c0c0;
    margin: 0 2px;
    padding: 0.35em 0.625em 0.75em;
}

/**
 * 1. Correct color not being inherited in IE 6/7/8/9.
 * 2. Correct text not wrapping in Firefox 3.
 * 3. Correct alignment displayed oddly in IE 6/7.
 */

legend {
    border: 0; /* 1 */
    padding: 0;
    white-space: normal; /* 2 */
    *margin-left: -7px; /* 3 */
}

/**
 * 1. Correct font size not being inherited in all browsers.
 * 2. Address margins set differently in IE 6/7, Firefox 3+, Safari 5,
 *    and Chrome.
 * 3. Improve appearance and consistency in all browsers.
 */

button,
input,
select,
textarea {
    font-size: 100%; /* 1 */
    margin: 0; /* 2 */
    vertical-align: baseline; /* 3 */
    *vertical-align: middle; /* 3 */
}

/**
 * Address Firefox 3+ setting `line-height` on `input` using `!important` in
 * the UA stylesheet.
 */

button,
input {
    line-height: normal;
}

/**
 * Address inconsistent `text-transform` inheritance for `button` and `select`.
 * All other form control elements do not inherit `text-transform` values.
 * Correct `button` style inheritance in Chrome, Safari 5+, and IE 6+.
 * Correct `select` style inheritance in Firefox 4+ and Opera.
 */

button,
select {
    text-transform: none;
}

/**
 * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
 *    and `video` controls.
 * 2. Correct inability to style clickable `input` types in iOS.
 * 3. Improve usability and consistency of cursor style between image-type
 *    `input` and others.
 * 4. Remove inner spacing in IE 7 without affecting normal text inputs.
 *    Known issue: inner spacing remains in IE 6.
 */

button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
    -webkit-appearance: button; /* 2 */
    cursor: pointer; /* 3 */
    *overflow: visible;  /* 4 */
}

/**
 * Re-set default cursor for disabled elements.
 */

button[disabled],
html input[disabled] {
    cursor: default;
}

/**
 * 1. Address box sizing set to content-box in IE 8/9.
 * 2. Remove excess padding in IE 8/9.
 * 3. Remove excess padding in IE 7.
 *    Known issue: excess padding remains in IE 6.
 */

input[type="checkbox"],
input[type="radio"] {
    box-sizing: border-box; /* 1 */
    padding: 0; /* 2 */
    *height: 13px; /* 3 */
    *width: 13px; /* 3 */
}

/**
 * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
 * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
 *    (include `-moz` to future-proof).
 */

input[type="search"] {
    -webkit-appearance: textfield; /* 1 */
    -moz-box-sizing: content-box;
    -webkit-box-sizing: content-box; /* 2 */
    box-sizing: content-box;
}

/**
 * Remove inner padding and search cancel button in Safari 5 and Chrome
 * on OS X.
 */

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
    -webkit-appearance: none;
}

/**
 * Remove inner padding and border in Firefox 3+.
 */

button::-moz-focus-inner,
input::-moz-focus-inner {
    border: 0;
    padding: 0;
}

/**
 * 1. Remove default vertical scrollbar in IE 6/7/8/9.
 * 2. Improve readability and alignment in all browsers.
 */

textarea {
    overflow: auto; /* 1 */
    vertical-align: top; /* 2 */
}

/* ==========================================================================
   Tables
   ========================================================================== */

/**
 * Remove most spacing between table cells.
 */

table {
    border-collapse: collapse;
    border-spacing: 0;
}

  </style>

  <style type="text/css">
  
  html, body {
    margin: 0;
    padding: 0;
    height: 100%;
  }
  body {
    background: #fff;
    font-family: "Source Sans Pro", "Helvetica Neueue", Helvetica, sans;
    font-weight: 300;
    font-size: 16px;
    line-height: 1.6em;
  }
  #content {
    width: 70%;
    max-width: 850px;
    float: left;
    padding: 30px 60px;
    border-left: 1px solid #ddd;
  }
  #sidebar {
    width: 25%;
    float: left;
    padding: 30px;
    overflow: hidden;
  }
  #nav {
    font-size: 130%;
    margin: 0 0 15px 0;
  }

  #top {
    display: block;
    position: fixed;
    bottom: 5px;
    left: 5px;
    font-size: .85em;
    text-transform: uppercase;
  }

  #footer {
    font-size: .75em;
    padding: 5px 30px;
    border-top: 1px solid #ddd;
    text-align: right;
  }
    #footer p {
      margin: 0 0 0 30px;
      display: inline-block;
    }

  h1, h2, h3, h4, h5 {
    font-weight: 300;
  }
  h1 {
    font-size: 2.5em;
    line-height: 1.1em;
    margin: 0 0 .50em 0;
  }

  h2 {
    font-size: 1.75em;
    margin: 1em 0 .50em 0;
  }

  h3 {
    margin: 25px 0 10px 0;
  }

  h4 {
    margin: 0;
    font-size: 105%;
  }

  a {
    color: #058;
    text-decoration: none;
    transition: color .3s ease-in-out;
  }

  a:hover {
    color: #e08524;
    transition: color .3s ease-in-out;
  }

  pre, code, .mono, .name {
    font-family: "Ubuntu Mono", "Cousine", "DejaVu Sans Mono", monospace;
  }

  .title .name {
    font-weight: bold;
  }
  .section-title {
    margin-top: 2em;
  }
  .ident {
    color: #900;
  }

  code {
    background: #f9f9f9;
  } 

  pre {
    background: #fefefe;
    border: 1px solid #ddd;
    box-shadow: 2px 2px 0 #f3f3f3;
    margin: 0 30px;
    padding: 15px 30px;
  }

  .codehilite {
    margin: 0 30px 10px 30px;
  }

    .codehilite pre {
      margin: 0;
    }
    .codehilite .err { background: #ff3300; color: #fff !important; } 

  table#module-list {
    font-size: 110%;
  }

    table#module-list tr td:first-child {
      padding-right: 10px;
      white-space: nowrap;
    }

    table#module-list td {
      vertical-align: top;
      padding-bottom: 8px;
    }

      table#module-list td p {
        margin: 0 0 7px 0;
      }

  .def {
    display: table;
  }

    .def p {
      display: table-cell;
      vertical-align: top;
      text-align: left;
    }

    .def p:first-child {
      white-space: nowrap;
    }

    .def p:last-child {
      width: 100%;
    }


  #index {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
    ul#index .class_name {
      /* font-size: 110%; */
      font-weight: bold;
    }
    #index ul {
      margin: 0;
    }

  .item {
    margin: 0 0 15px 0;
  }

    .item .class {
      margin: 0 0 25px 30px;
    }

      .item .class ul.class_list {
        margin: 0 0 20px 0;
      }

    .item .name {
      background: #fafafa;
      margin: 0;
      font-weight: bold;
      padding: 5px 10px;
      border-radius: 3px;
      display: inline-block;
      min-width: 40%;
    }
      .item .name:hover {
        background: #f6f6f6;
      }

    .item .empty_desc {
      margin: 0 0 5px 0;
      padding: 0;
    }

    .item .inheritance {
      margin: 3px 0 0 30px;
    }

    .item .inherited {
      color: #666;
    }

    .item .desc {
      padding: 0 8px;
      margin: 0;
    }

      .item .desc p {
        margin: 0 0 10px 0;
      }

    .source_cont {
      margin: 0;
      padding: 0;
    }

    .source_link a {
      background: #ffc300;
      font-weight: 400;
      font-size: .75em;
      text-transform: uppercase;
      color: #fff;
      text-shadow: 1px 1px 0 #f4b700;
      
      padding: 3px 8px;
      border-radius: 2px;
      transition: background .3s ease-in-out;
    }
      .source_link a:hover {
        background: #FF7200;
        text-shadow: none;
        transition: background .3s ease-in-out;
      }

    .source {
      display: none;
      max-height: 600px;
      overflow-y: scroll;
      margin-bottom: 15px;
    }

      .source .codehilite {
        margin: 0;
      }

  .desc h1, .desc h2, .desc h3 {
    font-size: 100% !important;
  }
  .clear {
    clear: both;
  }

  @media all and (max-width: 950px) {
    #sidebar {
      width: 35%;
    }
    #content {
      width: 65%;
    }
  }
  @media all and (max-width: 650px) {
    #top {
      display: none;
    }
    #sidebar {
      float: none;
      width: auto;
    }
    #content {
      float: none;
      width: auto;
      padding: 30px;
    }

    #index ul {
      padding: 0;
      margin-bottom: 15px;
    }
    #index ul li {
      display: inline-block;
      margin-right: 30px;
    }
    #footer {
      text-align: left;
    }
    #footer p {
      display: block;
      margin: inherit;
    }
  }

  /*****************************/

  </style>

  <style type="text/css">
  .codehilite .hll { background-color: #ffffcc }
.codehilite  { background: #f8f8f8; }
.codehilite .c { color: #408080; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #FF0000 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666666 } /* Operator */
.codehilite .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #BC7A00 } /* Comment.Preproc */
.codehilite .c1 { color: #408080; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #408080; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .gr { color: #FF0000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #00A000 } /* Generic.Inserted */
.codehilite .go { color: #888888 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #0044DD } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #7D9029 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.codehilite .no { color: #880000 } /* Name.Constant */
.codehilite .nd { color: #AA22FF } /* Name.Decorator */
.codehilite .ni { color: #999999; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #0000FF } /* Name.Function */
.codehilite .nl { color: #A0A000 } /* Name.Label */
.codehilite .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite .mb { color: #666666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666666 } /* Literal.Number.Float */
.codehilite .mh { color: #666666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666666 } /* Literal.Number.Oct */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #BB6688 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .il { color: #666666 } /* Literal.Number.Integer.Long */
  </style>

  <style type="text/css">
  
/* ==========================================================================
   EXAMPLE Media Queries for Responsive Design.
   These examples override the primary ('mobile first') styles.
   Modify as content requires.
   ========================================================================== */

@media only screen and (min-width: 35em) {
    /* Style adjustments for viewports that meet the condition */
}

@media print,
       (-o-min-device-pixel-ratio: 5/4),
       (-webkit-min-device-pixel-ratio: 1.25),
       (min-resolution: 120dpi) {
    /* Style adjustments for high resolution devices */
}

/* ==========================================================================
   Print styles.
   Inlined to avoid required HTTP connection: h5bp.com/r
   ========================================================================== */

@media print {
    * {
        background: transparent !important;
        color: #000 !important; /* Black prints faster: h5bp.com/s */
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    /*
     * Don't show links for images, or javascript/internal links
     */

    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; /* h5bp.com/t */
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    @page {
        margin: 0.5cm;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }
}

  </style>

  <script type="text/javascript">
  function toggle(id, $link) {
    $node = document.getElementById(id);
    if (!$node)
    return;
    if (!$node.style.display || $node.style.display == 'none') {
    $node.style.display = 'block';
    $link.innerHTML = 'Hide source &nequiv;';
    } else {
    $node.style.display = 'none';
    $link.innerHTML = 'Show source &equiv;';
    }
  }
  </script>
</head>
<body>
<a href="#" id="top">Top</a>

<div id="container">
    
  
  <div id="sidebar">
    <h1>Index</h1>
    <ul id="index">
    <li class="set"><h3><a href="#header-variables">Module variables</a></h3>
      
  <ul>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.MACHINE_EPSILON">MACHINE_EPSILON</a></li>
  </ul>

    </li>


    <li class="set"><h3><a href="#header-classes">Classes</a></h3>
      <ul>
        <li class="mono">
        <span class="class_name"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess">GaussianCopulaProcess</a></span>
        
          
  <ul>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.__init__">__init__</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.fit">fit</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.get_params">get_params</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.init_mappings">init_mappings</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.integrate_prediction">integrate_prediction</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping">mapping</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping_derivative">mapping_derivative</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping_inv">mapping_inv</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.predict">predict</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.predicted_RV">predicted_RV</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.reduced_likelihood_function">reduced_likelihood_function</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.score">score</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.set_params">set_params</a></li>
    <li class="mono"><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess.update_copula_params">update_copula_params</a></li>
  </ul>

        </li>
      </ul>
    </li>

    </ul>
  </div>

    <article id="content">
      
  

  


  <header id="section-intro">
  <h1 class="title"><span class="name">gcp_hpo.gcp.gcp</span> module</h1>
  
  
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp" class="source">
    <div class="codehilite"><pre><span class="c"># Author: Sebastien Dubois </span>
<span class="c">#		  for ALFA Group, CSAIL, MIT</span>

<span class="c"># The MIT License (MIT)</span>
<span class="c"># Copyright (c) 2015 Sebastien Dubois</span>

<span class="c"># Permission is hereby granted, free of charge, to any person obtaining a copy</span>
<span class="c"># of this software and associated documentation files (the &quot;Software&quot;), to deal</span>
<span class="c"># in the Software without restriction, including without limitation the rights</span>
<span class="c"># to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span>
<span class="c"># copies of the Software, and to permit persons to whom the Software is</span>
<span class="c"># furnished to do so, subject to the following conditions:</span>

<span class="c"># The above copyright notice and this permission notice shall be included in</span>
<span class="c"># all copies or substantial portions of the Software.</span>

<span class="c"># THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="c"># IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="c"># FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span>
<span class="c"># AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span>
<span class="c"># LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span>
<span class="c"># OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN</span>
<span class="c"># THE SOFTWARE.</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">linalg</span><span class="p">,</span> <span class="n">optimize</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">manhattan_distances</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">regression_models</span> <span class="k">as</span> <span class="n">regression</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">scipy.spatial</span> <span class="kn">import</span> <span class="n">distance</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">integrate</span>

<span class="kn">import</span> <span class="nn">sklearn_utils</span> <span class="kn">as</span> <span class="nn">sk_utils</span>
<span class="kn">from</span> <span class="nn">gcp_utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">MACHINE_EPSILON</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">double</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>



<span class="k">class</span> <span class="nc">GaussianCopulaProcess</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;The Gaussian Copula Process model class.</span>

<span class="sd">	**Parameters**</span>
<span class="sd">	----------</span>
<span class="sd">	`regr` : string or callable, optional  </span>
<span class="sd">		A regression function returning an array of outputs of the linear</span>
<span class="sd">		regression functional basis. The number of observations n_samples</span>
<span class="sd">		should be greater than the size p of this basis.</span>
<span class="sd">		Default assumes a simple constant regression trend.</span>
<span class="sd">		Available built-in regression models are:</span>

<span class="sd">			&#39;constant&#39;, &#39;linear&#39;, &#39;quadratic&#39;  </span>

<span class="sd">	`corr` : string or callable, optional  </span>
<span class="sd">		A stationary autocorrelation function returning the autocorrelation</span>
<span class="sd">		between two points x and x&#39;.</span>
<span class="sd">		Default assumes a squared-exponential autocorrelation model.</span>
<span class="sd">		Built-in correlation models are:</span>

<span class="sd">			&#39;squared_exponential&#39;, &#39;exponential_periodic&#39;  </span>

<span class="sd">	`beta0` : double array_like, optional  </span>
<span class="sd">		The regression weight vector to perform Ordinary Kriging (OK).</span>
<span class="sd">		Default assumes Universal Kriging (UK) so that the vector beta of</span>
<span class="sd">		regression weights is estimated using the maximum likelihood</span>
<span class="sd">		principle.  </span>

<span class="sd">	`verbose` : boolean, optional  </span>
<span class="sd">		A boolean specifying the verbose level.</span>
<span class="sd">		Default is verbose = False.  </span>

<span class="sd">	`theta` : double array_like, optional  </span>
<span class="sd">		An array with shape (n_features, ) or (1, ).</span>
<span class="sd">		The parameters in the autocorrelation model.</span>
<span class="sd">		theta is the starting point for the maximum likelihood estimation of the</span>
<span class="sd">		best set of parameters.  </span>
<span class="sd">		Default assumes isotropic autocorrelation model with theta0 = 1e-1.  </span>

<span class="sd">	`thetaL` : double array_like, optional  </span>
<span class="sd">		An array with shape matching theta0&#39;s.</span>
<span class="sd">		Lower bound on the autocorrelation parameters for maximum</span>
<span class="sd">		likelihood estimation.  </span>

<span class="sd">	`thetaU` : double array_like, optional  </span>
<span class="sd">		An array with shape matching theta0&#39;s.</span>
<span class="sd">		Upper bound on the autocorrelation parameters for maximum</span>
<span class="sd">		likelihood estimation.  </span>

<span class="sd">	`try_optimize` : boolean, optional  </span>
<span class="sd">		If True, perform maximum likelihood estimation to set the value of theta.</span>
<span class="sd">		Default is True.  </span>

<span class="sd">	`normalize` : boolean, optional  </span>
<span class="sd">		Input X and observations y are centered and reduced wrt</span>
<span class="sd">		means and standard deviations estimated from the n_samples</span>
<span class="sd">		observations provided.</span>
<span class="sd">		Default is normalize = True so that data is normalized to ease</span>
<span class="sd">		maximum likelihood estimation.  </span>

<span class="sd">	`reNormalizeY` : boolean, optional  </span>
<span class="sd">		Normalize the warped Y values, ie. the values mapping(Yt), before</span>
<span class="sd">		fitting a GP.</span>
<span class="sd">		Default is False.  </span>

<span class="sd">	`n_clusters` : int, optional  </span>
<span class="sd">		If n_clusters &gt; 1, a latent model is built by clustering the data with</span>
<span class="sd">		K-Means, into n_clusters clusters.</span>
<span class="sd">		Default is 1.  </span>

<span class="sd">	`coef_latent_mapping` : float, optional  </span>
<span class="sd">		If n_clusters &gt; 1, this coefficient is used to interpolate the mapping</span>
<span class="sd">		function on the whole space from the mapping functions learned on each</span>
<span class="sd">		cluster. This acts as a smoothing parameter : if coef_latent_mapping == 0.,</span>
<span class="sd">		each cluster contributes equally, and the greater it is the fewer</span>
<span class="sd">		mapping(x,y) takes into account the clusters in which x is not. </span>
<span class="sd">		Default is 0.5.  </span>

<span class="sd">	`mapWithNoise` : boolean, optional  </span>
<span class="sd">		If True and if Y outputs contain multiple noisy observations for the same</span>
<span class="sd">		x inputs, then all the noisy observations are used to compute Y&#39;s distribution</span>
<span class="sd">		and learn the mapping function.</span>
<span class="sd">		Otherwise, only the mean of the outputs, for a given input x, is considered.</span>
<span class="sd">		Default is False.  </span>

<span class="sd">	`useAllNoisyY` : boolean, optional  </span>
<span class="sd">		If True and if Y outputs contain multiple noisy observations for the same</span>
<span class="sd">		x inputs, then all the warped noisy observations are used to fit the GP.</span>
<span class="sd">		Otherwise, only the mean of the outputs, for a given input x, is considered.</span>
<span class="sd">		Default is False.  </span>

<span class="sd">	`model_noise` : string, optional  </span>
<span class="sd">		Method to model the noise.  </span>
<span class="sd">		If not None and if Y outputs contain multiple noisy observations for the same</span>
<span class="sd">		x inputs, then the nugget (see below) is estimated from the standard</span>
<span class="sd">		deviation of the multiple outputs for a given input x. Precisely the nugget</span>
<span class="sd">		is multiplied by 100 * std (as data is usually normed and noise is usually</span>
<span class="sd">		of the order of 1%).</span>
<span class="sd">		Default is None, methods currently available are :</span>

<span class="sd">			&#39;EGN&#39; (Estimated Gaussian Noise)  </span>

<span class="sd">	`nugget` : double or ndarray, optional  </span>
<span class="sd">		Introduce a nugget effect to allow smooth predictions from noisy</span>
<span class="sd">		data.  If nugget is an ndarray, it must be the same length as the</span>
<span class="sd">		number of data points used for the fit.</span>
<span class="sd">		The nugget is added to the diagonal of the assumed training covariance;</span>
<span class="sd">		in this way it acts as a Tikhonov regularization in the problem.  In</span>
<span class="sd">		the special case of the squared exponential correlation function, the</span>
<span class="sd">		nugget mathematically represents the variance of the input values.</span>
<span class="sd">		Default assumes a nugget close to machine precision for the sake of</span>
<span class="sd">		robustness (nugget = 10. * MACHINE_EPSILON).  </span>

<span class="sd">	`random_start` : int, optional  </span>
<span class="sd">		The number of times the Maximum Likelihood Estimation should be</span>
<span class="sd">		performed from a random starting point.</span>
<span class="sd">		The first MLE always uses the specified starting point (theta0),</span>
<span class="sd">		the next starting points are picked at random according to an</span>
<span class="sd">		exponential distribution (log-uniform on [thetaL, thetaU]).</span>
<span class="sd">		Default is 5.  </span>

<span class="sd">	`random_state` : integer or numpy.RandomState, optional  </span>
<span class="sd">		The generator used to shuffle the sequence of coordinates of theta in</span>
<span class="sd">		the Welch optimizer. If an integer is given, it fixes the seed.</span>
<span class="sd">		Defaults to the global numpy random number generator.  </span>


<span class="sd">	**Attributes**</span>
<span class="sd">	----------</span>
<span class="sd">	`theta_`: array  </span>
<span class="sd">		Specified theta OR the best set of autocorrelation parameters (the \</span>
<span class="sd">		sought maximizer of the reduced likelihood function).  </span>

<span class="sd">	`reduced_likelihood_function_value_`: array  </span>
<span class="sd">		The optimal reduced likelihood function value.  </span>
<span class="sd">	</span>
<span class="sd">	`centroids` : array of shape (n_clusters,n_features)  </span>
<span class="sd">		If n_clusters &gt; 1, the array of the clusters&#39; centroid.  </span>

<span class="sd">	`density_functions` : list of callable  </span>
<span class="sd">		List of length n_clusters, containing the density estimations \</span>
<span class="sd">		of the outputs on each cluster.  </span>

<span class="sd">	`mapping` : callable  </span>
<span class="sd">		The mapping function such that mapping(Yt) has a gaussian \</span>
<span class="sd">		distribution, where Yt is the output. \</span>
<span class="sd">		The mapping is learned based on the KDE estimation of Yt&#39;s distribution  </span>
<span class="sd">		</span>
<span class="sd">	`mapping_inv` : callable  </span>
<span class="sd">		The inverse mapping numerically computed by binomial search,\</span>
<span class="sd">		such that mapping_inv[mapping(.)] == mapping[mapping_inv(.)] == id  </span>
<span class="sd">	</span>
<span class="sd">	`mapping_derivative` : callable  </span>
<span class="sd">		The derivative of the mapping function.  </span>


<span class="sd">	**Notes**</span>
<span class="sd">	-----</span>
<span class="sd">	This code is based on scikit-learn&#39;s GP implementation.</span>

<span class="sd">	**References**</span>
<span class="sd">	----------</span>
<span class="sd">	On Gaussian processes:  </span>
<span class="sd">	.. [NLNS2002] `H.B. Nielsen, S.N. Lophaven, H. B. Nielsen and J.</span>
<span class="sd">		Sondergaard.  DACE - A MATLAB Kriging Toolbox.` (2002)</span>
<span class="sd">		http://www2.imm.dtu.dk/~hbn/dace/dace.pdf</span>

<span class="sd">	.. [WBSWM1992] `W.J. Welch, R.J. Buck, J. Sacks, H.P. Wynn, T.J. Mitchell,</span>
<span class="sd">		and M.D.  Morris (1992). Screening, predicting, and computer</span>
<span class="sd">		experiments.  Technometrics, 34(1) 15--25.`</span>
<span class="sd">		http://www.jstor.org/pss/1269548</span>

<span class="sd">	On Gaussian Copula processes:  </span>
<span class="sd">	.. Wilson, A. and Ghahramani, Z. Copula processes. In Advances in NIPS 23,</span>
<span class="sd">		pp. 2460-2468, 2010</span>
<span class="sd">	&quot;&quot;&quot;</span>

	<span class="n">_regression_types</span> <span class="o">=</span> <span class="p">{</span>
		<span class="s">&#39;constant&#39;</span><span class="p">:</span> <span class="n">regression</span><span class="o">.</span><span class="n">constant</span><span class="p">,</span>
		<span class="s">&#39;linear&#39;</span><span class="p">:</span> <span class="n">regression</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span>
		<span class="s">&#39;quadratic&#39;</span><span class="p">:</span> <span class="n">regression</span><span class="o">.</span><span class="n">quadratic</span><span class="p">}</span>


	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regr</span><span class="o">=</span><span class="s">&#39;constant&#39;</span><span class="p">,</span> 
				 <span class="n">corr</span><span class="o">=</span><span class="s">&#39;exponential_periodic&#39;</span><span class="p">,</span>
				 <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
				 <span class="n">theta</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">40</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="o">.</span><span class="mo">05</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mo">001</span><span class="p">,</span><span class="mf">10.</span><span class="p">]),</span>
                 <span class="n">thetaL</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">10.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="o">.</span><span class="mo">0001</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.0001</span><span class="p">,</span><span class="mf">1.</span><span class="p">]),</span>
                 <span class="n">thetaU</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">90</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1000.</span><span class="p">,</span><span class="mf">10.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="o">.</span><span class="mo">01</span><span class="p">,</span><span class="mf">100.</span><span class="p">]),</span> 
				 <span class="n">try_optimize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
				 <span class="n">random_start</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
				 <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
				 <span class="n">reNormalizeY</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
				 <span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
				 <span class="n">coef_latent_mapping</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
				 <span class="n">mapWithNoise</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
				 <span class="n">useAllNoisyY</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
				 <span class="n">model_noise</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
				 <span class="n">nugget</span><span class="o">=</span><span class="mf">10.</span> <span class="o">*</span> <span class="n">MACHINE_EPSILON</span><span class="p">,</span>
				 <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
 
		<span class="bp">self</span><span class="o">.</span><span class="n">regr</span> <span class="o">=</span> <span class="n">regr</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">beta0</span> <span class="o">=</span> <span class="bp">None</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="o">=</span> <span class="n">thetaL</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="o">=</span> <span class="n">thetaU</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">reNormalizeY</span> <span class="o">=</span> <span class="n">reNormalizeY</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="n">nugget</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s">&#39;fmin_cobyla&#39;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">random_start</span> <span class="o">=</span> <span class="n">random_start</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="o">=</span> <span class="n">try_optimize</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="bp">None</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">coef_latent_mapping</span> <span class="o">=</span> <span class="n">coef_latent_mapping</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span> <span class="o">=</span> <span class="n">mapWithNoise</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="o">=</span><span class="n">useAllNoisyY</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">corr</span> <span class="o">==</span> <span class="s">&#39;squared_exponential&#39;</span><span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="o">=</span> <span class="n">sq_exponential</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">0.1</span><span class="p">])</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">0.001</span><span class="p">])</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">10.</span><span class="p">])</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="o">=</span> <span class="n">exponential_periodic</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">model_noise</span> <span class="o">=</span> <span class="n">model_noise</span>
		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_noise</span> <span class="o">==</span> <span class="s">&#39;EGN&#39;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span><span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="o">=</span> <span class="bp">False</span>

	<span class="k">def</span> <span class="nf">mapping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
		<span class="k">if</span><span class="p">(</span><span class="n">normalize</span><span class="p">):</span>
			<span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span>
		<span class="n">v</span> <span class="o">=</span> <span class="mf">0.</span>
		<span class="c"># if t is too big, F_est(t) will be too close to 1</span>
		<span class="c"># this is an issue as in that case norm.ppf( F_est(t) ) will return Nan</span>
		<span class="c"># so we force F_est(t) to be smaller than 0.999999998 which corresponds to</span>
		<span class="c"># norm.ppf( F_est(t) ) being smaller than 6.3</span>
		<span class="c"># Normally doing this shouldn&#39;t cause any problem. But such extrem t values can</span>
		<span class="c"># be queried by the binomial search to invert the mapping (mapping_inv)</span>
		<span class="k">if</span><span class="p">(</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="mi">2047483647</span><span class="p">):</span>
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
				<span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
				<span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
				<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">):</span>
					<span class="c">## coefficients are :</span>
					<span class="c">#	 exp{  - sum [ (d_i /std_i) **2 ]  }</span>
					<span class="n">coefs</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_latent_mapping</span><span class="o">*</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">centroids</span><span class="p">[</span><span class="n">w</span><span class="p">])</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">clusters_std</span><span class="p">)</span><span class="o">**</span><span class="mf">2.</span> <span class="p">)</span> <span class="p">)</span>
					<span class="n">temp</span>  <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="n">w</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
					<span class="c"># if temp is too close to 1, norm.ppf(temp) == Nan</span>
					<span class="c"># if temp == 0, norm.ppf(temp) == -inf</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
					<span class="k">if</span><span class="p">(</span><span class="n">temp</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
						<span class="n">temp</span> <span class="o">=</span> <span class="mf">1e-10</span>
					<span class="n">val</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span> <span class="p">)</span> 
				
				<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coefs</span><span class="p">)</span>
				<span class="k">if</span><span class="p">(</span><span class="n">s</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
					<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">coefs</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span>
				<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">/</span> <span class="n">s</span>
				<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
				
			<span class="k">else</span><span class="p">:</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
				<span class="c"># if temp is too close to 1, norm.ppf(temp) == Nan</span>
				<span class="c"># if temp == 0, norm.ppf(temp) == -inf</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
				<span class="k">if</span><span class="p">(</span><span class="n">temp</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="mf">1e-10</span>
				<span class="n">v</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">v</span> <span class="o">=</span> <span class="mf">8.3</span>
			
		<span class="k">return</span> <span class="p">[</span><span class="n">v</span><span class="p">]</span>
		

	<span class="k">def</span> <span class="nf">mapping_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
		<span class="k">if</span><span class="p">(</span><span class="n">t</span><span class="o">&lt;=</span> <span class="mf">8.2</span><span class="p">):</span>
			<span class="k">def</span> <span class="nf">map</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
				<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
			<span class="n">lo</span><span class="p">,</span> <span class="n">hi</span> <span class="o">=</span> <span class="n">find_bounds</span><span class="p">(</span><span class="nb">map</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
			<span class="n">res</span> <span class="o">=</span> <span class="n">binary_search</span><span class="p">(</span><span class="nb">map</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">)</span>				
			<span class="k">return</span> <span class="p">[</span><span class="n">res</span><span class="p">]</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="k">return</span> <span class="p">[</span><span class="mi">2047483647</span><span class="p">]</span>


	<span class="k">def</span> <span class="nf">mapping_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
		<span class="c"># our mapping function is constant for t values greater than 2047483646</span>
		<span class="c"># so for such values mapping_derivate should be null</span>
		<span class="k">if</span><span class="p">(</span><span class="n">normalize</span><span class="p">):</span>
			<span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span>
		<span class="n">v</span> <span class="o">=</span> <span class="mf">0.</span>
		<span class="k">if</span><span class="p">(</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="mi">2047483646</span><span class="p">):</span>
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
				<span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
				<span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
				<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">):</span>
					<span class="c">## coefficients are :</span>
					<span class="c">#	 exp{  - sum [ (d_i /std_i) **2 ]  }</span>
					<span class="n">coefs</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_latent_mapping</span><span class="o">*</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">centroids</span><span class="p">[</span><span class="n">w</span><span class="p">])</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">clusters_std</span><span class="p">)</span><span class="o">**</span><span class="mf">2.</span> <span class="p">)</span> <span class="p">)</span>
					<span class="c"># computing Psi_i (t) </span>
					<span class="n">temp</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="n">w</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span> <span class="n">temp</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">)</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
					<span class="c"># pdf( Psi_i (t))</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
					<span class="c"># d_est_i / pdf(...)</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="n">w</span><span class="p">](</span><span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">temp</span>
					<span class="n">val</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span>
				<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coefs</span><span class="p">)</span>
				<span class="k">if</span><span class="p">(</span><span class="n">s</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
					<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">coefs</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span>
				<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">/</span> <span class="n">s</span>
				<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

			<span class="k">else</span><span class="p">:</span>
				<span class="n">temp</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span> <span class="n">temp</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">)</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
				<span class="c"># pdf( Psi (t))</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
				<span class="c"># d_est / pdf(...)</span>
				<span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">temp</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">v</span> <span class="o">=</span> <span class="mf">0.</span>
			
		<span class="k">return</span> <span class="p">(</span><span class="n">v</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span><span class="p">)</span>	


	<span class="k">def</span> <span class="nf">integrate_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">):</span>
		<span class="c"># utility function for the predict method</span>
		<span class="k">def</span> <span class="nf">f_to_integrate</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span> <span class="o">*</span> <span class="p">(</span><span class="n">u</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="p">)</span>
			<span class="k">return</span> <span class="n">temp</span>
		<span class="k">return</span><span class="p">(</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">f_to_integrate</span><span class="p">,</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">,</span><span class="n">epsrel</span> <span class="o">=</span><span class="mf">0.000000001</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>


	<span class="k">def</span> <span class="nf">predicted_RV</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
		<span class="c"># utility function for the predict method</span>
		<span class="k">def</span> <span class="nf">f_to_integrate</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span> <span class="o">*</span> <span class="p">(</span><span class="n">u</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="p">)</span>
			<span class="k">return</span> <span class="n">temp</span>
		<span class="k">return</span> <span class="n">f_to_integrate</span>


	<span class="k">def</span> <span class="nf">init_mappings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
		<span class="c"># We assume y is one-dimensional</span>
	
		<span class="c"># Perform KMeans and store results</span>
		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>

			<span class="n">clustering_pending</span> <span class="o">=</span> <span class="bp">True</span>
			<span class="k">while</span><span class="p">(</span><span class="n">clustering_pending</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span><span class="mi">1</span> <span class="p">):</span>
				<span class="n">clustering_pending</span> <span class="o">=</span> <span class="bp">False</span>
				<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
				<span class="n">all_data</span> <span class="o">=</span> <span class="p">[]</span>
				<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
					<span class="n">all_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
				<span class="n">all_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">all_data</span><span class="p">)</span>
				<span class="n">windows_idx</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">all_data</span><span class="p">)</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">centroids</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
		
				<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
					<span class="k">print</span><span class="p">(</span><span class="s">&#39;All data shape :&#39;</span><span class="p">,</span><span class="n">all_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
					<span class="k">print</span> <span class="p">(</span><span class="s">&quot;Centroids&quot;</span><span class="p">)</span>
					<span class="k">print</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_std</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">centroids</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span><span class="o">*</span><span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span><span class="p">)</span>
				
				<span class="c"># Compute the density function for each sub-window</span>
				<span class="n">density_functions</span> <span class="o">=</span> <span class="p">[]</span>
				<span class="n">clusters_std</span> <span class="o">=</span> <span class="p">[]</span>
				<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
					<span class="n">detailed_windows_idx</span> <span class="o">=</span><span class="n">reshape_cluster_labels</span><span class="p">(</span><span class="n">windows_idx</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span><span class="p">)</span>
				<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">):</span>
					<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
						<span class="n">cluster_points_y_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span><span class="p">[</span> <span class="n">detailed_windows_idx</span> <span class="o">==</span> <span class="n">w</span><span class="p">])[:,</span><span class="mi">0</span><span class="p">])</span>
					<span class="k">else</span><span class="p">:</span>
						<span class="n">cluster_points_y_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[</span> <span class="n">windows_idx</span> <span class="o">==</span> <span class="n">w</span><span class="p">])[:,</span><span class="mi">0</span><span class="p">])</span>
					<span class="n">clusters_std</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span> <span class="n">windows_idx</span> <span class="o">==</span> <span class="n">w</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">)</span> <span class="c">### this is a (Xdim) array</span>
					<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
						<span class="k">print</span><span class="p">(</span><span class="s">&#39;cluster &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="s">&#39; size &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cluster_points_y_values</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
					<span class="k">if</span><span class="p">(</span><span class="n">cluster_points_y_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
						<span class="n">clustering_pending</span> <span class="o">=</span> <span class="bp">True</span>
					<span class="k">else</span><span class="p">:</span>
						<span class="n">density_functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="n">cluster_points_y_values</span><span class="p">)</span> <span class="p">)</span>
				
				<span class="k">if</span><span class="p">(</span><span class="n">clustering_pending</span><span class="p">):</span>
					<span class="k">print</span> <span class="p">(</span><span class="s">&#39;Fail to build &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#39; clusters&#39;</span><span class="p">)</span>
					<span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">-=</span> <span class="mi">1</span>

				<span class="k">else</span><span class="p">:</span>
					<span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="n">density_functions</span><span class="p">)</span>
					<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">density_functions</span>
					<span class="n">clusters_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">clusters_std</span><span class="p">)</span>
					<span class="n">clusters_std</span><span class="p">[</span><span class="n">clusters_std</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
					<span class="bp">self</span><span class="o">.</span><span class="n">clusters_std</span> <span class="o">=</span> <span class="n">clusters_std</span>

					<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
						<span class="k">print</span><span class="p">(</span><span class="s">&#39;---STD---&#39;</span><span class="p">)</span>
						<span class="k">print</span><span class="p">(</span><span class="n">clusters_std</span><span class="p">)</span>	

			<span class="k">if</span><span class="p">(</span><span class="n">clustering_pending</span><span class="p">):</span>
				<span class="c"># n_cluster == 1</span>
				<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
					<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>	

		<span class="k">else</span><span class="p">:</span>
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>
		
		
	<span class="k">def</span> <span class="nf">update_copula_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

		<span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="n">y</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
		<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
		
		<span class="c"># Normalize data</span>
		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reNormalizeY</span><span class="p">):</span>
			<span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">y_std</span><span class="p">[</span><span class="n">y_std</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">y_mean</span> <span class="o">=</span> <span class="mf">0.</span>
			<span class="n">y_std</span> <span class="o">=</span> <span class="mf">1.</span>
		<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_std</span>

		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">obs_noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_noise</span> <span class="o">==</span> <span class="s">&#39;EGN&#39;</span> <span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">*</span><span class="p">(</span> <span class="p">(</span> <span class="mf">10.</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs_noise</span> <span class="p">)</span> <span class="o">**</span> <span class="mf">2.</span> <span class="p">)</span>

		<span class="c"># Calculate matrix of distances D between samples</span>
		<span class="n">D</span><span class="p">,</span> <span class="n">ij</span> <span class="o">=</span> <span class="n">l1_cross_distances</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
		<span class="c">#if (np.min(np.sum(D, axis=1)) == 0.):</span>
		<span class="c">#	raise Exception(&quot;Multiple input features cannot have the same&quot;</span>
		<span class="c">#					&quot; target value.&quot;)</span>

		<span class="n">n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="c"># Regression matrix and parameters</span>
		<span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
		<span class="n">n_samples_F</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
			<span class="n">p</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
		<span class="k">if</span> <span class="n">n_samples_F</span> <span class="o">!=</span> <span class="n">n_samples</span><span class="p">:</span>
			<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Number of rows in F and X do not match. Most &quot;</span>
							<span class="s">&quot;likely something is going wrong with the &quot;</span>
							<span class="s">&quot;regression model.&quot;</span><span class="p">)</span>
		<span class="k">if</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="n">n_samples_F</span><span class="p">:</span>
			<span class="k">raise</span> <span class="ne">Exception</span><span class="p">((</span><span class="s">&quot;Ordinary least squares problem is undetermined &quot;</span>
							 <span class="s">&quot;n_samples=</span><span class="si">%d</span><span class="s"> must be greater than the &quot;</span>
							 <span class="s">&quot;regression model size p=</span><span class="si">%d</span><span class="s">.&quot;</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">D</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">ij</span> <span class="o">=</span> <span class="n">ij</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">F</span> <span class="o">=</span> <span class="n">F</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">=</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span>
			
			
	<span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">detailed_y_obs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">obs_noise</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		The Gaussian Copula Process model fitting method.</span>

<span class="sd">		Parameters</span>
<span class="sd">		----------</span>
<span class="sd">		`X` : double array_like  </span>
<span class="sd">			An array with shape (n_samples, n_features) with the input at which</span>
<span class="sd">			observations were made.  </span>

<span class="sd">		`y` : double array_like  </span>
<span class="sd">			An array with shape (n_samples, ) or shape (n_samples, n_targets)</span>
<span class="sd">			with the observations of the output to be predicted.</span>
<span class="sd">			Currently only 1D targets are supported.  </span>

<span class="sd">		`detailed_y_obs` : double list of list  </span>
<span class="sd">			A list of length n_samples where entry at position i corresponds to </span>
<span class="sd">			the mutiple noisy observations (given as a list) of the input value X[i,:], </span>
<span class="sd">			and whose mean is y[i].  </span>
<span class="sd">			If not None, it can be used to learn the mapping function or fit the GP,</span>
<span class="sd">			see parameters mapWithNoise and useAllNoisyY of the GaussianCopulaProcess class.  </span>

<span class="sd">		`obs_noise` : double array  </span>
<span class="sd">			An array of shape (n_samples,) corresponding to the estimated noise</span>
<span class="sd">			in the observed y outputs.  </span>
<span class="sd">			If not None, it can be used to model the noise with the Estimated</span>
<span class="sd">			Gaussian Noise method, see the model_noise parameter of the </span>
<span class="sd">			GaussianCopulaProcess class.  </span>

<span class="sd">		Returns</span>
<span class="sd">		-------</span>
<span class="sd">		`gcp` : self  </span>
<span class="sd">			A fitted Gaussian Copula Process model object awaiting data to perform</span>
<span class="sd">			predictions.  </span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="c"># Run input checks</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">()</span>
		<span class="n">X</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">array2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
		<span class="c"># Check if all CV obs are given</span>
		<span class="c"># and if so, convert this list of list to array</span>
		<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
			<span class="n">detailed_X</span><span class="p">,</span><span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="n">listOfList_toArray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">detailed_y_obs</span><span class="p">)</span>	

		<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">y_ndim_</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span>
		<span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
			<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
			<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
				<span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="n">detailed_raw_y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="k">print</span><span class="p">(</span><span class="s">&#39;Warning: code is not ready for y outputs with dimension &gt; 1&#39;</span><span class="p">)</span>
		
		<span class="c"># Reshape theta if it is one dimensional and X is not</span>
		<span class="n">x_dim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
		<span class="c">#if not(self.theta.ndim == 1):</span>
		<span class="c">#	print(&#39;Warning : theta has not the right shape&#39;)</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x_dim</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="p">)</span><span class="o">.</span><span class="n">T</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x_dim</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="p">)</span><span class="o">.</span><span class="n">T</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x_dim</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="p">)</span><span class="o">.</span><span class="n">T</span>
		<span class="c">#print(&#39;theta has new shape &#39;+str(self.theta.shape))</span>
			
		<span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>		
		<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">check_arrays</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

		<span class="c"># Check shapes of DOE &amp; observations</span>
		<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
		<span class="n">_</span><span class="p">,</span> <span class="n">n_targets</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>

		<span class="c"># Run input checks</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

		<span class="c"># Normalize data or don&#39;t</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
			<span class="n">X_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">X_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">X_std</span><span class="p">[</span><span class="n">X_std</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
			<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_std</span>

			<span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">raw_y_std</span><span class="p">[</span><span class="n">raw_y_std</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
			<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">raw_y_std</span>
			
			<span class="k">if</span><span class="p">(</span><span class="n">obs_noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
				<span class="n">obs_noise</span> <span class="o">=</span> <span class="n">obs_noise</span> <span class="o">/</span> <span class="n">raw_y_std</span>

			<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
				<span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">detailed_raw_y</span> <span class="o">-</span> <span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">raw_y_std</span>
				<span class="n">detailed_X</span> <span class="o">=</span> <span class="p">(</span><span class="n">detailed_X</span> <span class="o">-</span> <span class="n">X_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_std</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">X_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
			<span class="n">X_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
		
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>		
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

		<span class="c"># Set attributes</span>

		<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="n">detailed_raw_y</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span> <span class="o">=</span> <span class="n">detailed_X</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="bp">None</span>			
			<span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span> <span class="o">=</span> <span class="bp">None</span>			
		
		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span>
			
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">raw_y_mean</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">raw_y_std</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="o">-</span><span class="mf">500.</span><span class="p">,</span> <span class="mf">5.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)])</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span> <span class="o">=</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">X_std</span>

			<span class="c"># initialize mapping only if needed, i.e. it hasn&#39;t be done </span>
			<span class="c"># yet of if we want to optimize the GCP hyperparameters</span>
			<span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)):</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">init_mappings</span><span class="p">()</span>
		
		<span class="k">elif</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="n">y</span>

			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">raw_y_mean</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">raw_y_std</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="o">-</span><span class="mf">500.</span><span class="p">,</span> <span class="mf">5.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)])</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span> <span class="o">=</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">X_std</span>

			<span class="c"># initialize mapping only if needed, i.e. it hasn&#39;t be done </span>
			<span class="c"># yet of if we want to optimize the GCP hyperparameters</span>
			<span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)):</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">init_mappings</span><span class="p">()</span>

			<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span>

		<span class="k">else</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="n">y</span>

			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">raw_y_mean</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">raw_y_std</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="o">-</span><span class="mf">500.</span><span class="p">,</span> <span class="mf">5.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)])</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span> <span class="o">=</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">X_std</span>

			<span class="c"># initialize mapping only if needed, i.e. it hasn&#39;t be done </span>
			<span class="c"># yet of if we want to optimize the GCP hyperparameters</span>
			<span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)):</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">init_mappings</span><span class="p">()</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">obs_noise</span> <span class="o">=</span> <span class="n">obs_noise</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">update_copula_params</span><span class="p">()</span>
		
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span><span class="p">:</span>
		    <span class="c"># Maximum Likelihood Estimation of the parameters</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
				<span class="k">print</span><span class="p">(</span><span class="s">&quot;Performing Maximum Likelihood Estimation of the &quot;</span>
					  <span class="s">&quot;autocorrelation parameters...&quot;</span><span class="p">)</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">,</span> <span class="n">par</span> <span class="o">=</span> \
				<span class="bp">self</span><span class="o">.</span><span class="n">_arg_max_reduced_likelihood_function</span><span class="p">()</span>
			<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">):</span>
				<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Bad parameter region. &quot;</span>
								<span class="s">&quot;Try increasing upper bound&quot;</span><span class="p">)</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="c"># Given parameters</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
				<span class="k">print</span><span class="p">(</span><span class="s">&quot;Given autocorrelation parameters. &quot;</span>
					  <span class="s">&quot;Computing Gaussian Process model parameters...&quot;</span><span class="p">)</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">,</span> <span class="n">par</span> <span class="o">=</span> \
				<span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">()</span>
			<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">):</span>
				<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Bad point. Try increasing theta0.&quot;</span><span class="p">)</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;beta&#39;</span><span class="p">]</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;gamma&#39;</span><span class="p">]</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;sigma2&#39;</span><span class="p">]</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;C&#39;</span><span class="p">]</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">Ft</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;Ft&#39;</span><span class="p">]</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;G&#39;</span><span class="p">]</span>

		<span class="k">return</span> <span class="bp">self</span>

	<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">eval_MSE</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transformY</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">returnRV</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">integratedPrediction</span><span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">eval_confidence_bounds</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">coef_bound</span><span class="o">=</span><span class="mf">1.96</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		This function evaluates the Gaussian Process model at x.  </span>

<span class="sd">		Parameters</span>
<span class="sd">		----------</span>
<span class="sd">		`X` : array_like  </span>
<span class="sd">			An array with shape (n_eval, n_features) giving the point(s) at</span>
<span class="sd">			which the prediction(s) should be made.  </span>

<span class="sd">		`eval_MSE` : boolean, optional  </span>
<span class="sd">			A boolean specifying whether the Mean Squared Error should be</span>
<span class="sd">			evaluated or not.  </span>
<span class="sd">			Default assumes evalMSE = False and evaluates only the BLUP (mean</span>
<span class="sd">			prediction).  </span>

<span class="sd">		`transformY` : boolean, optional  </span>
<span class="sd">			A boolean specifying if the predicted values should correspond to</span>
<span class="sd">			the same space as the data given to the fit method, or to the</span>
<span class="sd">			warped space (in which the GP is fitted).</span>
<span class="sd">			Default is True. Setting to False can be useful to compute the Expected</span>
<span class="sd">			Improvement in an optimization process.  </span>

<span class="sd">		`returnRV` : boolean, optional  </span>
<span class="sd">			A boolean specifying if the method should return the predicted random variables</span>
<span class="sd">			at x instead of a float number.  </span>
<span class="sd">			Default is False.  </span>

<span class="sd">		`integratedPrediction` : boolean, optional  </span>
<span class="sd">			A boolean specifying if the method should return the fully Bayesian</span>
<span class="sd">			prediction, ie compute the expectation given the posterior in the</span>
<span class="sd">			original space. If False, the returned value is the inverse value</span>
<span class="sd">			(by the mapping function) of the GP prediction. This is much more faster</span>
<span class="sd">			as the integratedPrediction needs to numerically compute the integral.</span>
<span class="sd">			Default is False.  </span>

<span class="sd">		`eval_confidence_bounds` : boolean, optional  </span>
<span class="sd">			A boolean specifying if the method should return the confidence bounds.</span>
<span class="sd">			Because of the non-linearity of the mapping function, this cannot be computed</span>
<span class="sd">			directly with the MSE, but needs to invert the mapping function.  </span>
<span class="sd">			Default is False. If True, coef_bound specifies the boundary to compute.  </span>

<span class="sd">		`coef_bound` : float, optional  </span>
<span class="sd">			A float specifying the confidence bounds to compute. Upper and lower</span>
<span class="sd">			confidence bounds are computed as the inverse of m + coef_bound*sigma</span>
<span class="sd">			where m and sigma are the mean and the std of the posterior in the GP</span>
<span class="sd">			space.  </span>
<span class="sd">			Default is 1.96 which corresponds to the 95% confidence bounds.  </span>

<span class="sd">		`batch_size` : integer, optional  </span>
<span class="sd">			An integer giving the maximum number of points that can be</span>
<span class="sd">			evaluated simultaneously (depending on the available memory).</span>
<span class="sd">			Default is None so that all given points are evaluated at the same</span>
<span class="sd">			time.  </span>

<span class="sd">		Returns</span>
<span class="sd">		-------</span>
<span class="sd">		`y` : array_like, shape (n_samples,)  </span>
<span class="sd">			Prediction at x.</span>

<span class="sd">		`MSE` : array_like, optional (if eval_MSE == True)  </span>
<span class="sd">			Mean Squared Error at x.</span>

<span class="sd">		`LCB` : array_like, optional (if eval_confidence_bounds == True)  </span>
<span class="sd">			Lower confidence bound.</span>

<span class="sd">		`UCB` : array_like, optional (if eval_confidence_bounds == True)  </span>
<span class="sd">			Upper confidence bound.</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="c"># Check input shapes</span>
		<span class="n">X</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">array2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
		<span class="n">n_eval</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
		<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span>
		<span class="n">n_samples_y</span><span class="p">,</span> <span class="n">n_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span>

		<span class="k">if</span><span class="p">(</span><span class="n">n_targets</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
			<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&#39;More than one target in the Y outputs. </span><span class="se">\</span>
<span class="s">							  Currently only 1D outputs are handled&#39;</span><span class="p">)</span>

		<span class="c"># Run input checks</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

		<span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">n_features</span><span class="p">:</span>
			<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s">&quot;The number of features in X (X.shape[1] = </span><span class="si">%d</span><span class="s">) &quot;</span>
							  <span class="s">&quot;should match the number of features used &quot;</span>
							  <span class="s">&quot;for fit() &quot;</span>
							  <span class="s">&quot;which is </span><span class="si">%d</span><span class="s">.&quot;</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_features</span><span class="p">))</span>

		<span class="c"># Normalize input</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
			<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span>
			
		<span class="c"># Initialize output</span>
		<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_eval</span><span class="p">)</span>
		<span class="k">if</span> <span class="n">eval_MSE</span><span class="p">:</span>
			<span class="n">MSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_eval</span><span class="p">)</span>

		<span class="c"># Get pairwise componentwise L1-distances to the input training set</span>
		<span class="n">dx</span> <span class="o">=</span> <span class="n">manhattan_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">sum_over_features</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
		<span class="c"># Get regression function and correlation</span>
		<span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
		<span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">dx</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>

		<span class="c"># Scaled predictor</span>
		<span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>

		<span class="c"># Predictor</span>
		<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">*</span> <span class="n">y_</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span>

		<span class="c"># transform the warped y, modeled as a Gaussian, to the real y</span>
		<span class="n">size</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="n">warped_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
		
		<span class="k">if</span><span class="p">(</span><span class="n">transformY</span><span class="p">):</span>
			<span class="k">if</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">8.2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)])</span> <span class="o">&gt;</span><span class="mi">0</span><span class="p">):</span>
				<span class="k">print</span><span class="p">(</span><span class="s">&#39;Warning : mapping_inversion failed&#39;</span><span class="p">)</span>
			<span class="n">real_y</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_inv</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
			<span class="n">real_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">real_y</span><span class="p">)</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span>
			<span class="n">y</span> <span class="o">=</span> <span class="n">real_y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span>
		
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_ndim_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
			<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
			<span class="n">warped_y</span> <span class="o">=</span> <span class="n">warped_y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

		<span class="c"># Mean Squared Error</span>
		<span class="k">if</span> <span class="n">eval_MSE</span><span class="p">:</span>
			<span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span>
			<span class="k">if</span> <span class="n">C</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
				<span class="c"># Light storage mode (need to recompute C, F, Ft and G)</span>
				<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
					<span class="k">print</span><span class="p">(</span><span class="s">&quot;This GaussianProcess used &#39;light&#39; storage mode &quot;</span>
						  <span class="s">&quot;at instantiation. Need to recompute &quot;</span>
						  <span class="s">&quot;autocorrelation matrix...&quot;</span><span class="p">)</span>
				<span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span> <span class="o">=</span> \
					<span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">()</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;C&#39;</span><span class="p">]</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">Ft</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;Ft&#39;</span><span class="p">]</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;G&#39;</span><span class="p">]</span>

			<span class="n">rt</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta0</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
				<span class="c"># Universal Kriging</span>
				<span class="n">u</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
											<span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Ft</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rt</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="c"># Ordinary Kriging</span>
				<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_targets</span><span class="p">,</span> <span class="n">n_eval</span><span class="p">))</span>

			<span class="n">MSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_targets</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
						 <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="p">(</span><span class="n">rt</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
						  <span class="o">+</span> <span class="p">(</span><span class="n">u</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:])</span>
			<span class="n">MSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">MSE</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_targets</span><span class="p">)</span>

			<span class="c"># Mean Squared Error might be slightly negative depending on</span>
			<span class="c"># machine precision: force to zero!</span>
			<span class="n">MSE</span><span class="p">[</span><span class="n">MSE</span> <span class="o">&lt;</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>

			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_ndim_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
				<span class="n">MSE</span> <span class="o">=</span> <span class="n">MSE</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
				<span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">MSE</span><span class="p">)</span>
				<span class="k">if</span><span class="p">(</span><span class="n">returnRV</span><span class="p">):</span>
					<span class="k">return</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">predicted_RV</span><span class="p">([</span><span class="n">warped_y</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="k">if</span><span class="p">(</span><span class="n">eval_confidence_bounds</span><span class="p">):</span>
						<span class="k">if</span> <span class="ow">not</span><span class="p">(</span><span class="n">transformY</span><span class="p">):</span>
							<span class="k">print</span><span class="p">(</span><span class="s">&#39;Warning, transformY set to False but trying to evaluate conf bounds&#39;</span><span class="p">)</span>
						<span class="n">warped_y_with_boundL</span> <span class="o">=</span> <span class="n">warped_y</span> <span class="o">-</span> <span class="n">coef_bound</span> <span class="o">*</span> <span class="n">sigma</span>
						<span class="n">warped_y_with_boundU</span> <span class="o">=</span> <span class="n">warped_y</span> <span class="o">+</span> <span class="n">coef_bound</span> <span class="o">*</span> <span class="n">sigma</span>
						<span class="n">pred_with_boundL</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_inv</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">warped_y_with_boundL</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="p">]</span> <span class="p">)</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span>
						<span class="n">pred_with_boundU</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_inv</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">warped_y_with_boundU</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span> <span class="p">)</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span>
						
						<span class="k">if</span><span class="p">(</span><span class="n">integratedPrediction</span><span class="p">):</span>
							<span class="n">lb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span> <span class="o">-</span> <span class="mf">3.</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span><span class="p">)</span>
							<span class="n">ub</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span> <span class="o">+</span> <span class="mf">3.</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span><span class="p">)</span>
							<span class="k">print</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">)</span>
							<span class="n">integrated_real_y</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">integrate_prediction</span><span class="p">([</span><span class="n">warped_y</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
							<span class="n">integrated_real_y</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">integrated_real_y</span><span class="p">)</span>
							<span class="k">print</span><span class="p">(</span><span class="s">&#39;Integrated prediction&#39;</span><span class="p">)</span>
							<span class="k">return</span> <span class="n">integrated_real_y</span><span class="p">,</span><span class="n">MSE</span><span class="p">,</span><span class="n">pred_with_boundL</span><span class="p">,</span><span class="n">pred_with_boundU</span>

						<span class="k">else</span><span class="p">:</span>
							<span class="k">return</span> <span class="n">y</span><span class="p">,</span><span class="n">MSE</span><span class="p">,</span><span class="n">pred_with_boundL</span><span class="p">,</span><span class="n">pred_with_boundU</span>

						
					<span class="k">else</span><span class="p">:</span>
						<span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">MSE</span>
			
			<span class="k">else</span><span class="p">:</span>
				<span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">MSE</span>

		<span class="k">else</span><span class="p">:</span>
			<span class="k">return</span> <span class="n">y</span>


	<span class="k">def</span> <span class="nf">reduced_likelihood_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		This function determines the BLUP parameters and evaluates the reduced</span>
<span class="sd">		likelihood function for the given autocorrelation parameters theta.</span>

<span class="sd">		Maximizing this function wrt the autocorrelation parameters theta is</span>
<span class="sd">		equivalent to maximizing the likelihood of the assumed joint Gaussian</span>
<span class="sd">		distribution of the observations y evaluated onto the design of</span>
<span class="sd">		experiments X.</span>

<span class="sd">		Parameters</span>
<span class="sd">		----------</span>
<span class="sd">		`theta` : array_like, optional</span>
<span class="sd">			An array containing the autocorrelation parameters at which the</span>
<span class="sd">			Gaussian Process model parameters should be determined.</span>
<span class="sd">			Default uses the built-in autocorrelation parameters</span>
<span class="sd">			(ie ``theta = self.theta_``).</span>

<span class="sd">		Returns</span>
<span class="sd">		-------</span>
<span class="sd">		`reduced_likelihood_function_value` : double</span>
<span class="sd">			The value of the reduced likelihood function associated to the</span>
<span class="sd">			given autocorrelation parameters theta.</span>

<span class="sd">		`par` : dict</span>
<span class="sd">			A dictionary containing the requested Gaussian Process model</span>
<span class="sd">			parameters:</span>

<span class="sd">				sigma2</span>
<span class="sd">						Gaussian Process variance.</span>
<span class="sd">				beta</span>
<span class="sd">						Generalized least-squares regression weights for</span>
<span class="sd">						Universal Kriging or given beta0 for Ordinary</span>
<span class="sd">						Kriging.</span>
<span class="sd">				gamma</span>
<span class="sd">						Gaussian Process weights.</span>
<span class="sd">				C</span>
<span class="sd">						Cholesky decomposition of the correlation matrix [R].</span>
<span class="sd">				Ft</span>
<span class="sd">						Solution of the linear equation system : [R] x Ft = F</span>
<span class="sd">				G</span>
<span class="sd">						QR decomposition of the matrix Ft.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		
		<span class="k">if</span> <span class="n">theta</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
			<span class="c"># Use built-in autocorrelation parameters</span>
			<span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span>

		<span class="c"># Initialize output</span>
		<span class="n">reduced_likelihood_function_value</span> <span class="o">=</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
		<span class="n">par</span> <span class="o">=</span> <span class="p">{}</span>

		<span class="c"># Retrieve data</span>
		<span class="n">n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="n">D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span>
		<span class="n">ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ij</span>
		<span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span>

		<span class="k">if</span> <span class="n">D</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
			<span class="c"># Light storage mode (need to recompute D, ij and F)</span>
			<span class="n">D</span><span class="p">,</span> <span class="n">ij</span> <span class="o">=</span> <span class="n">l1_cross_distances</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
			<span class="c">#if (np.min(np.sum(D, axis=1)) == 0.):</span>
			<span class="c">#	raise Exception(&quot;Multiple X are not allowed&quot;)</span>
			<span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

		<span class="c"># Set up R</span>
		<span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
		<span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="p">)</span>
		<span class="n">R</span><span class="p">[</span><span class="n">ij</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ij</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">r</span>
		<span class="n">R</span><span class="p">[</span><span class="n">ij</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ij</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">r</span>

		<span class="c"># Cholesky decomposition of R</span>
		<span class="k">try</span><span class="p">:</span>
			<span class="n">C</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
		<span class="k">except</span> <span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
			<span class="k">return</span> <span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span>

		<span class="c"># Get generalized least squares solution</span>
		<span class="n">Ft</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
		<span class="k">try</span><span class="p">:</span>
			<span class="n">Q</span><span class="p">,</span> <span class="n">G</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
		<span class="k">except</span><span class="p">:</span>
			<span class="c">#/usr/lib/python2.6/dist-packages/scipy/linalg/decomp.py:1177:</span>
			<span class="c"># DeprecationWarning: qr econ argument will be removed after scipy</span>
			<span class="c"># 0.7. The economy transform will then be available through the</span>
			<span class="c"># mode=&#39;economic&#39; argument.</span>
			<span class="n">Q</span><span class="p">,</span> <span class="n">G</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;economic&#39;</span><span class="p">)</span>
			<span class="k">pass</span>

		<span class="n">sv</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
		<span class="n">rcondG</span> <span class="o">=</span> <span class="n">sv</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">sv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="k">if</span> <span class="n">rcondG</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
			<span class="c"># Check F</span>
			<span class="n">sv</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
			<span class="n">condF</span> <span class="o">=</span> <span class="n">sv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">sv</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
			<span class="k">if</span> <span class="n">condF</span> <span class="o">&gt;</span> <span class="mf">1e15</span><span class="p">:</span>
				<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;F is too ill conditioned. Poor combination &quot;</span>
								<span class="s">&quot;of regression model and observations.&quot;</span><span class="p">)</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="c"># Ft is too ill conditioned, get out (try different theta)</span>
				<span class="k">return</span> <span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span>

		<span class="n">Yt</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta0</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
			<span class="c"># Universal Kriging</span>
			<span class="n">beta</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Yt</span><span class="p">))</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="c"># Ordinary Kriging</span>
			<span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta0</span><span class="p">)</span>

		<span class="n">rho</span> <span class="o">=</span> <span class="n">Yt</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
		<span class="n">sigma2</span> <span class="o">=</span> <span class="p">(</span><span class="n">rho</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_samples</span>
		<span class="c"># The determinant of R is equal to the squared product of the diagonal</span>
		<span class="c"># elements of its Cholesky decomposition C</span>
		<span class="n">detR</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">C</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">/</span> <span class="n">n_samples</span><span class="p">))</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>

		<span class="c"># Compute/Organize output</span>
		<span class="n">reduced_likelihood_function_value</span> <span class="o">=</span> <span class="o">-</span> <span class="n">sigma2</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="n">detR</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;sigma2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">**</span> <span class="mf">2.</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;beta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;gamma&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rho</span><span class="p">)</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;C&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">C</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;Ft&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Ft</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;G&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">G</span>

		<span class="k">return</span> <span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span>

	<span class="k">def</span> <span class="nf">_arg_max_reduced_likelihood_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		This function estimates the autocorrelation parameters theta as the</span>
<span class="sd">		maximizer of the reduced likelihood function.</span>
<span class="sd">		(Minimization of the opposite reduced likelihood function is used for</span>
<span class="sd">		convenience)</span>

<span class="sd">		Parameters</span>
<span class="sd">		----------</span>
<span class="sd">		`self` : All parameters are stored in the Gaussian Process model object.</span>

<span class="sd">		Returns</span>
<span class="sd">		-------</span>
<span class="sd">		`optimal_theta` : array_like</span>
<span class="sd">			The best set of autocorrelation parameters (the sought maximizer of</span>
<span class="sd">			the reduced likelihood function).</span>

<span class="sd">		`optimal_reduced_likelihood_function_value` : double</span>
<span class="sd">			The optimal reduced likelihood function value.</span>

<span class="sd">		`optimal_par` : dict</span>
<span class="sd">			The BLUP parameters associated to thetaOpt.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		
		<span class="c"># Initialize output</span>
		<span class="n">best_optimal_theta</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="n">best_optimal_rlf_value</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="n">best_optimal_par</span> <span class="o">=</span> <span class="p">[]</span>

		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
			<span class="k">print</span><span class="p">(</span><span class="s">&quot;The chosen optimizer is: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">))</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_start</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
				<span class="k">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_start</span><span class="p">)</span> <span class="o">+</span> <span class="s">&quot; random starts are required.&quot;</span><span class="p">)</span>

		<span class="n">percent_completed</span> <span class="o">=</span> <span class="mf">0.</span>

		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="s">&#39;fmin_cobyla&#39;</span><span class="p">:</span>

			<span class="k">def</span> <span class="nf">minus_reduced_likelihood_function</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
				<span class="n">x_reshaped</span> <span class="o">=</span> <span class="n">theta_backToRealShape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
				<span class="k">return</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">(</span>
					<span class="n">theta</span><span class="o">=</span><span class="mf">10.</span> <span class="o">**</span> <span class="n">x_reshaped</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
						
			<span class="n">constraints</span> <span class="o">=</span> <span class="p">[]</span>
			<span class="c"># http://stackoverflow.com/questions/25985868/scipy-why-isnt-cobyla-respecting-constraint</span>
			
			<span class="c"># Cobyla takes only one dimensional array</span>
			<span class="n">conL</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">theta_toOneDim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">))</span>
			<span class="n">conU</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">theta_toOneDim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">))</span>
			
			<span class="k">def</span> <span class="nf">kernel_coef</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
				<span class="k">return</span><span class="p">(</span><span class="mf">100.</span> <span class="o">-</span> <span class="p">((</span><span class="mf">10.</span> <span class="o">**</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="mf">10.</span> <span class="o">**</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="mf">10.</span> <span class="o">**</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="p">))</span>
			
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
				<span class="n">n_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>	
			<span class="k">else</span><span class="p">:</span>
				<span class="n">n_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">size</span>
			<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_idx</span><span class="p">):</span>
				<span class="n">lower</span> <span class="o">=</span> <span class="n">conL</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
				<span class="n">upper</span> <span class="o">=</span> <span class="n">conU</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
				<span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">lower</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">idx</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span>
				<span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">upper</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">idx</span><span class="p">:</span> <span class="n">b</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
			
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
				<span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kernel_coef</span><span class="p">)</span>
			
			<span class="n">k</span><span class="o">=</span><span class="mi">0</span>
			<span class="n">k2</span> <span class="o">=</span> <span class="mi">0</span>
			<span class="k">while</span><span class="p">(</span> <span class="p">(</span><span class="n">k</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_start</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">k2</span> <span class="o">&lt;</span> <span class="mi">50</span><span class="p">)):</span>
					
				<span class="k">if</span> <span class="p">(</span><span class="n">k</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">k2</span> <span class="o">==</span><span class="mi">0</span><span class="p">):</span>
					<span class="c"># Use specified starting point as first guess</span>
					<span class="n">theta0</span> <span class="o">=</span> <span class="n">theta_toOneDim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)</span>

				<span class="k">else</span><span class="p">:</span>
					<span class="c"># Generate a random starting point log10-uniformly</span>
					<span class="c"># distributed between bounds</span>
					<span class="n">log10theta0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">)</span> \
						<span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
							<span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span>
														  <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">)</span>
					<span class="n">theta0</span> <span class="o">=</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">theta_toOneDim</span><span class="p">(</span><span class="n">log10theta0</span><span class="p">)</span>
					
				<span class="c"># Run Cobyla</span>
				<span class="k">try</span><span class="p">:</span>
					<span class="n">params</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">theta0</span><span class="p">)</span>
					<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
						<span class="k">print</span><span class="p">(</span><span class="s">&#39;try &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
						
					<span class="n">log10_opt</span> <span class="o">=</span> \
						<span class="n">optimize</span><span class="o">.</span><span class="n">fmin_cobyla</span><span class="p">(</span><span class="n">minus_reduced_likelihood_function</span><span class="p">,</span>
											 <span class="n">params</span><span class="p">,</span>
											 <span class="n">constraints</span><span class="p">,</span>
											 <span class="n">maxfun</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span>
											 <span class="c">#rhobeg=2.0,</span>
											 <span class="n">rhoend</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
											 <span class="n">iprint</span><span class="o">=</span><span class="mi">0</span>
											 <span class="p">)</span>
					<span class="n">opt_minus_rlf</span> <span class="o">=</span> <span class="n">minus_reduced_likelihood_function</span><span class="p">(</span><span class="n">log10_opt</span><span class="p">)</span>
					<span class="c">#print(opt_minus_rlf)</span>
					<span class="n">log10_optimal_theta</span> <span class="o">=</span> <span class="n">theta_backToRealShape</span><span class="p">(</span><span class="n">log10_opt</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
					
				<span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">ve</span><span class="p">:</span>
					<span class="n">opt_minus_rlf</span> <span class="o">=</span> <span class="mf">999999999.</span>
					<span class="n">k2</span> <span class="o">+=</span> <span class="mi">1</span>
					<span class="k">raise</span> <span class="n">ve</span>
					<span class="k">print</span><span class="p">(</span><span class="s">&#39;Warning, exception raised in Cobyla&#39;</span><span class="p">)</span>
				
				<span class="k">if</span><span class="p">(</span><span class="n">opt_minus_rlf</span> <span class="o">!=</span> <span class="mf">999999999.</span> <span class="p">):</span>
				
					<span class="n">optimal_theta</span> <span class="o">=</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">log10_optimal_theta</span>
					<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
						<span class="k">print</span><span class="p">(</span><span class="n">optimal_theta</span><span class="p">)</span>
					<span class="n">optimal_rlf_value</span><span class="p">,</span> <span class="n">optimal_par</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">optimal_theta</span><span class="p">)</span>

					<span class="c"># Compare the new optimizer to the best previous one</span>
					<span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
						<span class="k">if</span> <span class="n">optimal_rlf_value</span> <span class="o">&gt;</span> <span class="n">best_optimal_rlf_value</span><span class="p">:</span>
							<span class="n">best_optimal_rlf_value</span> <span class="o">=</span> <span class="n">optimal_rlf_value</span>
							<span class="n">best_optimal_par</span> <span class="o">=</span> <span class="n">optimal_par</span>
							<span class="n">best_optimal_theta</span> <span class="o">=</span> <span class="n">optimal_theta</span>
					<span class="k">else</span><span class="p">:</span>
						<span class="n">best_optimal_rlf_value</span> <span class="o">=</span> <span class="n">optimal_rlf_value</span>
						<span class="n">best_optimal_par</span> <span class="o">=</span> <span class="n">optimal_par</span>
						<span class="n">best_optimal_theta</span> <span class="o">=</span> <span class="n">optimal_theta</span>
					<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_start</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
						<span class="k">if</span> <span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="n">k</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_start</span> <span class="o">&gt;</span> <span class="n">percent_completed</span><span class="p">:</span>
							<span class="n">percent_completed</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="n">k</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_start</span>
							<span class="k">print</span><span class="p">(</span><span class="s">&quot;</span><span class="si">%s</span><span class="s"> completed&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">5</span> <span class="o">*</span> <span class="n">percent_completed</span><span class="p">))</span>
					
					<span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>
					
				<span class="k">else</span><span class="p">:</span>
					<span class="n">k2</span> <span class="o">+=</span> <span class="mi">1</span>
					<span class="k">if</span><span class="p">(</span><span class="n">k2</span> <span class="o">==</span> <span class="mi">50</span> <span class="ow">and</span> <span class="n">k</span><span class="o">==</span><span class="mi">0</span><span class="p">):</span>
						<span class="k">print</span><span class="p">(</span><span class="s">&quot;Cobyla Optimization failed. Try increasing the ``nugget``&quot;</span><span class="p">)</span>
						<span class="n">best_optimal_theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span>
						<span class="n">best_optimal_rlf_value</span><span class="p">,</span> <span class="n">best_optimal_par</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">best_optimal_theta</span><span class="p">)</span>
									
			<span class="n">optimal_rlf_value</span> <span class="o">=</span> <span class="n">best_optimal_rlf_value</span>
			<span class="n">optimal_par</span> <span class="o">=</span> <span class="n">best_optimal_par</span>
			<span class="n">optimal_theta</span> <span class="o">=</span> <span class="n">best_optimal_theta</span>
			
		<span class="k">else</span><span class="p">:</span>
			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s">&quot;This optimizer (&#39;</span><span class="si">%s</span><span class="s">&#39;) is not &quot;</span>
									  <span class="s">&quot;implemented yet. Please contribute!&quot;</span>
									  <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>

		<span class="k">return</span> <span class="n">optimal_theta</span><span class="p">,</span> <span class="n">optimal_rlf_value</span><span class="p">,</span> <span class="n">optimal_par</span>


	<span class="k">def</span> <span class="nf">_check_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

		<span class="c"># Check regression model</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">):</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="p">:</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">regr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">]</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;regr should be one of </span><span class="si">%s</span><span class="s"> or callable, &quot;</span>
								 <span class="s">&quot;</span><span class="si">%s</span><span class="s"> was given.&quot;</span>
								 <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">))</span>

		<span class="c"># Check correlation model</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">):</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_correlation_types</span><span class="p">:</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_correlation_types</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">]</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;corr should be one of </span><span class="si">%s</span><span class="s"> or callable, &quot;</span>
								 <span class="s">&quot;</span><span class="si">%s</span><span class="s"> was given.&quot;</span>
								 <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_correlation_types</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">))</span>


		<span class="c"># Force verbose type to bool</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

		<span class="c"># Force normalize type to bool</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">)</span>

		<span class="c"># Check nugget value</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="p">)</span>
		<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.</span><span class="p">:</span>
			<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;nugget must be positive or zero.&quot;</span><span class="p">)</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">n_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
				<span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="o">.</span><span class="n">shape</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[(),</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,)]):</span>
			<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;nugget must be either a scalar &quot;</span>
							 <span class="s">&quot;or array of length n_samples.&quot;</span><span class="p">)</span>


		<span class="c"># Force random_start type to int</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">random_start</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_start</span><span class="p">)</span>
</pre></div>

  </div>

  </header>

  <section id="section-items">
    <h2 class="section-title" id="header-variables">Module variables</h2>
      <div class="item">
      <p id="gcp_hpo.gcp.gcp.MACHINE_EPSILON" class="name">var <span class="ident">MACHINE_EPSILON</span></p>
      
  
  <div class="source_cont">
</div>

      </div>


    <h2 class="section-title" id="header-classes">Classes</h2>
      
      <div class="item">
      <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess" class="name">class <span class="ident">GaussianCopulaProcess</span></p>
      
  
    <div class="desc"><p>The Gaussian Copula Process model class.</p>
<h2><strong>Parameters</strong></h2>
<p><code>regr</code> : string or callable, optional<br />
        A regression function returning an array of outputs of the linear
        regression functional basis. The number of observations n_samples
        should be greater than the size p of this basis.
        Default assumes a simple constant regression trend.
        Available built-in regression models are:</p>
<div class="codehilite"><pre>            &#39;constant&#39;, &#39;linear&#39;, &#39;quadratic&#39;
</pre></div>


<p><code>corr</code> : string or callable, optional<br />
        A stationary autocorrelation function returning the autocorrelation
        between two points x and x'.
        Default assumes a squared-exponential autocorrelation model.
        Built-in correlation models are:</p>
<div class="codehilite"><pre>            &#39;squared_exponential&#39;, &#39;exponential_periodic&#39;
</pre></div>


<p><code>beta0</code> : double array_like, optional<br />
        The regression weight vector to perform Ordinary Kriging (OK).
        Default assumes Universal Kriging (UK) so that the vector beta of
        regression weights is estimated using the maximum likelihood
        principle.  </p>
<p><code>verbose</code> : boolean, optional<br />
        A boolean specifying the verbose level.
        Default is verbose = False.  </p>
<p><code>theta</code> : double array_like, optional<br />
        An array with shape (n_features, ) or (1, ).
        The parameters in the autocorrelation model.
        theta is the starting point for the maximum likelihood estimation of the
        best set of parameters.<br />
        Default assumes isotropic autocorrelation model with theta0 = 1e-1.  </p>
<p><code>thetaL</code> : double array_like, optional<br />
        An array with shape matching theta0's.
        Lower bound on the autocorrelation parameters for maximum
        likelihood estimation.  </p>
<p><code>thetaU</code> : double array_like, optional<br />
        An array with shape matching theta0's.
        Upper bound on the autocorrelation parameters for maximum
        likelihood estimation.  </p>
<p><code>try_optimize</code> : boolean, optional<br />
        If True, perform maximum likelihood estimation to set the value of theta.
        Default is True.  </p>
<p><code>normalize</code> : boolean, optional<br />
        Input X and observations y are centered and reduced wrt
        means and standard deviations estimated from the n_samples
        observations provided.
        Default is normalize = True so that data is normalized to ease
        maximum likelihood estimation.  </p>
<p><code>reNormalizeY</code> : boolean, optional<br />
        Normalize the warped Y values, ie. the values mapping(Yt), before
        fitting a GP.
        Default is False.  </p>
<p><code>n_clusters</code> : int, optional<br />
        If n_clusters &gt; 1, a latent model is built by clustering the data with
        K-Means, into n_clusters clusters.
        Default is 1.  </p>
<p><code>coef_latent_mapping</code> : float, optional<br />
        If n_clusters &gt; 1, this coefficient is used to interpolate the mapping
        function on the whole space from the mapping functions learned on each
        cluster. This acts as a smoothing parameter : if coef_latent_mapping == 0.,
        each cluster contributes equally, and the greater it is the fewer
        mapping(x,y) takes into account the clusters in which x is not. 
        Default is 0.5.  </p>
<p><code>mapWithNoise</code> : boolean, optional<br />
        If True and if Y outputs contain multiple noisy observations for the same
        x inputs, then all the noisy observations are used to compute Y's distribution
        and learn the mapping function.
        Otherwise, only the mean of the outputs, for a given input x, is considered.
        Default is False.  </p>
<p><code>useAllNoisyY</code> : boolean, optional<br />
        If True and if Y outputs contain multiple noisy observations for the same
        x inputs, then all the warped noisy observations are used to fit the GP.
        Otherwise, only the mean of the outputs, for a given input x, is considered.
        Default is False.  </p>
<p><code>model_noise</code> : string, optional<br />
        Method to model the noise.<br />
        If not None and if Y outputs contain multiple noisy observations for the same
        x inputs, then the nugget (see below) is estimated from the standard
        deviation of the multiple outputs for a given input x. Precisely the nugget
        is multiplied by 100 * std (as data is usually normed and noise is usually
        of the order of 1%).
        Default is None, methods currently available are :</p>
<div class="codehilite"><pre>            &#39;EGN&#39; (Estimated Gaussian Noise)
</pre></div>


<p><code>nugget</code> : double or ndarray, optional<br />
        Introduce a nugget effect to allow smooth predictions from noisy
        data.  If nugget is an ndarray, it must be the same length as the
        number of data points used for the fit.
        The nugget is added to the diagonal of the assumed training covariance;
        in this way it acts as a Tikhonov regularization in the problem.  In
        the special case of the squared exponential correlation function, the
        nugget mathematically represents the variance of the input values.
        Default assumes a nugget close to machine precision for the sake of
        robustness (nugget = 10. * MACHINE_EPSILON).  </p>
<p><code>random_start</code> : int, optional<br />
        The number of times the Maximum Likelihood Estimation should be
        performed from a random starting point.
        The first MLE always uses the specified starting point (theta0),
        the next starting points are picked at random according to an
        exponential distribution (log-uniform on [thetaL, thetaU]).
        Default is 5.  </p>
<p><code>random_state</code> : integer or numpy.RandomState, optional<br />
        The generator used to shuffle the sequence of coordinates of theta in
        the Welch optimizer. If an integer is given, it fixes the seed.
        Defaults to the global numpy random number generator.  </p>
<h2><strong>Attributes</strong></h2>
<p><code>theta_</code>: array<br />
        Specified theta OR the best set of autocorrelation parameters (the              sought maximizer of the reduced likelihood function).  </p>
<p><code>reduced_likelihood_function_value_</code>: array<br />
        The optimal reduced likelihood function value.  </p>
<p><code>centroids</code> : array of shape (n_clusters,n_features)<br />
        If n_clusters &gt; 1, the array of the clusters' centroid.  </p>
<p><code>density_functions</code> : list of callable<br />
        List of length n_clusters, containing the density estimations           of the outputs on each cluster.  </p>
<p><code>mapping</code> : callable<br />
        The mapping function such that mapping(Yt) has a gaussian               distribution, where Yt is the output.           The mapping is learned based on the KDE estimation of Yt's distribution  </p>
<p><code>mapping_inv</code> : callable<br />
        The inverse mapping numerically computed by binomial search,            such that mapping_inv[mapping(.)] == mapping[mapping_inv(.)] == id  </p>
<p><code>mapping_derivative</code> : callable<br />
        The derivative of the mapping function.  </p>
<h2><strong>Notes</strong></h2>
<p>This code is based on scikit-learn's GP implementation.</p>
<h2><strong>References</strong></h2>
<p>On Gaussian processes:<br />
.. [NLNS2002] <code>H.B. Nielsen, S.N. Lophaven, H. B. Nielsen and J.
        Sondergaard.  DACE - A MATLAB Kriging Toolbox.</code> (2002)
        http://www2.imm.dtu.dk/~hbn/dace/dace.pdf</p>
<p>.. [WBSWM1992] <code>W.J. Welch, R.J. Buck, J. Sacks, H.P. Wynn, T.J. Mitchell,
        and M.D.  Morris (1992). Screening, predicting, and computer
        experiments.  Technometrics, 34(1) 15--25.</code>
        http://www.jstor.org/pss/1269548</p>
<p>On Gaussian Copula processes:<br />
.. Wilson, A. and Ghahramani, Z. Copula processes. In Advances in NIPS 23,
        pp. 2460-2468, 2010</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess" class="source">
    <div class="codehilite"><pre><span class="k">class</span> <span class="nc">GaussianCopulaProcess</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;The Gaussian Copula Process model class.</span>

<span class="sd">	**Parameters**</span>
<span class="sd">	----------</span>
<span class="sd">	`regr` : string or callable, optional  </span>
<span class="sd">		A regression function returning an array of outputs of the linear</span>
<span class="sd">		regression functional basis. The number of observations n_samples</span>
<span class="sd">		should be greater than the size p of this basis.</span>
<span class="sd">		Default assumes a simple constant regression trend.</span>
<span class="sd">		Available built-in regression models are:</span>

<span class="sd">			&#39;constant&#39;, &#39;linear&#39;, &#39;quadratic&#39;  </span>

<span class="sd">	`corr` : string or callable, optional  </span>
<span class="sd">		A stationary autocorrelation function returning the autocorrelation</span>
<span class="sd">		between two points x and x&#39;.</span>
<span class="sd">		Default assumes a squared-exponential autocorrelation model.</span>
<span class="sd">		Built-in correlation models are:</span>

<span class="sd">			&#39;squared_exponential&#39;, &#39;exponential_periodic&#39;  </span>

<span class="sd">	`beta0` : double array_like, optional  </span>
<span class="sd">		The regression weight vector to perform Ordinary Kriging (OK).</span>
<span class="sd">		Default assumes Universal Kriging (UK) so that the vector beta of</span>
<span class="sd">		regression weights is estimated using the maximum likelihood</span>
<span class="sd">		principle.  </span>

<span class="sd">	`verbose` : boolean, optional  </span>
<span class="sd">		A boolean specifying the verbose level.</span>
<span class="sd">		Default is verbose = False.  </span>

<span class="sd">	`theta` : double array_like, optional  </span>
<span class="sd">		An array with shape (n_features, ) or (1, ).</span>
<span class="sd">		The parameters in the autocorrelation model.</span>
<span class="sd">		theta is the starting point for the maximum likelihood estimation of the</span>
<span class="sd">		best set of parameters.  </span>
<span class="sd">		Default assumes isotropic autocorrelation model with theta0 = 1e-1.  </span>

<span class="sd">	`thetaL` : double array_like, optional  </span>
<span class="sd">		An array with shape matching theta0&#39;s.</span>
<span class="sd">		Lower bound on the autocorrelation parameters for maximum</span>
<span class="sd">		likelihood estimation.  </span>

<span class="sd">	`thetaU` : double array_like, optional  </span>
<span class="sd">		An array with shape matching theta0&#39;s.</span>
<span class="sd">		Upper bound on the autocorrelation parameters for maximum</span>
<span class="sd">		likelihood estimation.  </span>

<span class="sd">	`try_optimize` : boolean, optional  </span>
<span class="sd">		If True, perform maximum likelihood estimation to set the value of theta.</span>
<span class="sd">		Default is True.  </span>

<span class="sd">	`normalize` : boolean, optional  </span>
<span class="sd">		Input X and observations y are centered and reduced wrt</span>
<span class="sd">		means and standard deviations estimated from the n_samples</span>
<span class="sd">		observations provided.</span>
<span class="sd">		Default is normalize = True so that data is normalized to ease</span>
<span class="sd">		maximum likelihood estimation.  </span>

<span class="sd">	`reNormalizeY` : boolean, optional  </span>
<span class="sd">		Normalize the warped Y values, ie. the values mapping(Yt), before</span>
<span class="sd">		fitting a GP.</span>
<span class="sd">		Default is False.  </span>

<span class="sd">	`n_clusters` : int, optional  </span>
<span class="sd">		If n_clusters &gt; 1, a latent model is built by clustering the data with</span>
<span class="sd">		K-Means, into n_clusters clusters.</span>
<span class="sd">		Default is 1.  </span>

<span class="sd">	`coef_latent_mapping` : float, optional  </span>
<span class="sd">		If n_clusters &gt; 1, this coefficient is used to interpolate the mapping</span>
<span class="sd">		function on the whole space from the mapping functions learned on each</span>
<span class="sd">		cluster. This acts as a smoothing parameter : if coef_latent_mapping == 0.,</span>
<span class="sd">		each cluster contributes equally, and the greater it is the fewer</span>
<span class="sd">		mapping(x,y) takes into account the clusters in which x is not. </span>
<span class="sd">		Default is 0.5.  </span>

<span class="sd">	`mapWithNoise` : boolean, optional  </span>
<span class="sd">		If True and if Y outputs contain multiple noisy observations for the same</span>
<span class="sd">		x inputs, then all the noisy observations are used to compute Y&#39;s distribution</span>
<span class="sd">		and learn the mapping function.</span>
<span class="sd">		Otherwise, only the mean of the outputs, for a given input x, is considered.</span>
<span class="sd">		Default is False.  </span>

<span class="sd">	`useAllNoisyY` : boolean, optional  </span>
<span class="sd">		If True and if Y outputs contain multiple noisy observations for the same</span>
<span class="sd">		x inputs, then all the warped noisy observations are used to fit the GP.</span>
<span class="sd">		Otherwise, only the mean of the outputs, for a given input x, is considered.</span>
<span class="sd">		Default is False.  </span>

<span class="sd">	`model_noise` : string, optional  </span>
<span class="sd">		Method to model the noise.  </span>
<span class="sd">		If not None and if Y outputs contain multiple noisy observations for the same</span>
<span class="sd">		x inputs, then the nugget (see below) is estimated from the standard</span>
<span class="sd">		deviation of the multiple outputs for a given input x. Precisely the nugget</span>
<span class="sd">		is multiplied by 100 * std (as data is usually normed and noise is usually</span>
<span class="sd">		of the order of 1%).</span>
<span class="sd">		Default is None, methods currently available are :</span>

<span class="sd">			&#39;EGN&#39; (Estimated Gaussian Noise)  </span>

<span class="sd">	`nugget` : double or ndarray, optional  </span>
<span class="sd">		Introduce a nugget effect to allow smooth predictions from noisy</span>
<span class="sd">		data.  If nugget is an ndarray, it must be the same length as the</span>
<span class="sd">		number of data points used for the fit.</span>
<span class="sd">		The nugget is added to the diagonal of the assumed training covariance;</span>
<span class="sd">		in this way it acts as a Tikhonov regularization in the problem.  In</span>
<span class="sd">		the special case of the squared exponential correlation function, the</span>
<span class="sd">		nugget mathematically represents the variance of the input values.</span>
<span class="sd">		Default assumes a nugget close to machine precision for the sake of</span>
<span class="sd">		robustness (nugget = 10. * MACHINE_EPSILON).  </span>

<span class="sd">	`random_start` : int, optional  </span>
<span class="sd">		The number of times the Maximum Likelihood Estimation should be</span>
<span class="sd">		performed from a random starting point.</span>
<span class="sd">		The first MLE always uses the specified starting point (theta0),</span>
<span class="sd">		the next starting points are picked at random according to an</span>
<span class="sd">		exponential distribution (log-uniform on [thetaL, thetaU]).</span>
<span class="sd">		Default is 5.  </span>

<span class="sd">	`random_state` : integer or numpy.RandomState, optional  </span>
<span class="sd">		The generator used to shuffle the sequence of coordinates of theta in</span>
<span class="sd">		the Welch optimizer. If an integer is given, it fixes the seed.</span>
<span class="sd">		Defaults to the global numpy random number generator.  </span>


<span class="sd">	**Attributes**</span>
<span class="sd">	----------</span>
<span class="sd">	`theta_`: array  </span>
<span class="sd">		Specified theta OR the best set of autocorrelation parameters (the \</span>
<span class="sd">		sought maximizer of the reduced likelihood function).  </span>

<span class="sd">	`reduced_likelihood_function_value_`: array  </span>
<span class="sd">		The optimal reduced likelihood function value.  </span>
<span class="sd">	</span>
<span class="sd">	`centroids` : array of shape (n_clusters,n_features)  </span>
<span class="sd">		If n_clusters &gt; 1, the array of the clusters&#39; centroid.  </span>

<span class="sd">	`density_functions` : list of callable  </span>
<span class="sd">		List of length n_clusters, containing the density estimations \</span>
<span class="sd">		of the outputs on each cluster.  </span>

<span class="sd">	`mapping` : callable  </span>
<span class="sd">		The mapping function such that mapping(Yt) has a gaussian \</span>
<span class="sd">		distribution, where Yt is the output. \</span>
<span class="sd">		The mapping is learned based on the KDE estimation of Yt&#39;s distribution  </span>
<span class="sd">		</span>
<span class="sd">	`mapping_inv` : callable  </span>
<span class="sd">		The inverse mapping numerically computed by binomial search,\</span>
<span class="sd">		such that mapping_inv[mapping(.)] == mapping[mapping_inv(.)] == id  </span>
<span class="sd">	</span>
<span class="sd">	`mapping_derivative` : callable  </span>
<span class="sd">		The derivative of the mapping function.  </span>


<span class="sd">	**Notes**</span>
<span class="sd">	-----</span>
<span class="sd">	This code is based on scikit-learn&#39;s GP implementation.</span>

<span class="sd">	**References**</span>
<span class="sd">	----------</span>
<span class="sd">	On Gaussian processes:  </span>
<span class="sd">	.. [NLNS2002] `H.B. Nielsen, S.N. Lophaven, H. B. Nielsen and J.</span>
<span class="sd">		Sondergaard.  DACE - A MATLAB Kriging Toolbox.` (2002)</span>
<span class="sd">		http://www2.imm.dtu.dk/~hbn/dace/dace.pdf</span>

<span class="sd">	.. [WBSWM1992] `W.J. Welch, R.J. Buck, J. Sacks, H.P. Wynn, T.J. Mitchell,</span>
<span class="sd">		and M.D.  Morris (1992). Screening, predicting, and computer</span>
<span class="sd">		experiments.  Technometrics, 34(1) 15--25.`</span>
<span class="sd">		http://www.jstor.org/pss/1269548</span>

<span class="sd">	On Gaussian Copula processes:  </span>
<span class="sd">	.. Wilson, A. and Ghahramani, Z. Copula processes. In Advances in NIPS 23,</span>
<span class="sd">		pp. 2460-2468, 2010</span>
<span class="sd">	&quot;&quot;&quot;</span>

	<span class="n">_regression_types</span> <span class="o">=</span> <span class="p">{</span>
		<span class="s">&#39;constant&#39;</span><span class="p">:</span> <span class="n">regression</span><span class="o">.</span><span class="n">constant</span><span class="p">,</span>
		<span class="s">&#39;linear&#39;</span><span class="p">:</span> <span class="n">regression</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span>
		<span class="s">&#39;quadratic&#39;</span><span class="p">:</span> <span class="n">regression</span><span class="o">.</span><span class="n">quadratic</span><span class="p">}</span>


	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regr</span><span class="o">=</span><span class="s">&#39;constant&#39;</span><span class="p">,</span> 
				 <span class="n">corr</span><span class="o">=</span><span class="s">&#39;exponential_periodic&#39;</span><span class="p">,</span>
				 <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
				 <span class="n">theta</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">40</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="o">.</span><span class="mo">05</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mo">001</span><span class="p">,</span><span class="mf">10.</span><span class="p">]),</span>
                 <span class="n">thetaL</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">10.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="o">.</span><span class="mo">0001</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.0001</span><span class="p">,</span><span class="mf">1.</span><span class="p">]),</span>
                 <span class="n">thetaU</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">90</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1000.</span><span class="p">,</span><span class="mf">10.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="o">.</span><span class="mo">01</span><span class="p">,</span><span class="mf">100.</span><span class="p">]),</span> 
				 <span class="n">try_optimize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
				 <span class="n">random_start</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
				 <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
				 <span class="n">reNormalizeY</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
				 <span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
				 <span class="n">coef_latent_mapping</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
				 <span class="n">mapWithNoise</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
				 <span class="n">useAllNoisyY</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
				 <span class="n">model_noise</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
				 <span class="n">nugget</span><span class="o">=</span><span class="mf">10.</span> <span class="o">*</span> <span class="n">MACHINE_EPSILON</span><span class="p">,</span>
				 <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
 
		<span class="bp">self</span><span class="o">.</span><span class="n">regr</span> <span class="o">=</span> <span class="n">regr</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">beta0</span> <span class="o">=</span> <span class="bp">None</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="o">=</span> <span class="n">thetaL</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="o">=</span> <span class="n">thetaU</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">reNormalizeY</span> <span class="o">=</span> <span class="n">reNormalizeY</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="n">nugget</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s">&#39;fmin_cobyla&#39;</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">random_start</span> <span class="o">=</span> <span class="n">random_start</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="o">=</span> <span class="n">try_optimize</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="bp">None</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">coef_latent_mapping</span> <span class="o">=</span> <span class="n">coef_latent_mapping</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span> <span class="o">=</span> <span class="n">mapWithNoise</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="o">=</span><span class="n">useAllNoisyY</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">corr</span> <span class="o">==</span> <span class="s">&#39;squared_exponential&#39;</span><span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="o">=</span> <span class="n">sq_exponential</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">0.1</span><span class="p">])</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">0.001</span><span class="p">])</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">10.</span><span class="p">])</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="o">=</span> <span class="n">exponential_periodic</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">model_noise</span> <span class="o">=</span> <span class="n">model_noise</span>
		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_noise</span> <span class="o">==</span> <span class="s">&#39;EGN&#39;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span><span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="o">=</span> <span class="bp">False</span>

	<span class="k">def</span> <span class="nf">mapping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
		<span class="k">if</span><span class="p">(</span><span class="n">normalize</span><span class="p">):</span>
			<span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span>
		<span class="n">v</span> <span class="o">=</span> <span class="mf">0.</span>
		<span class="c"># if t is too big, F_est(t) will be too close to 1</span>
		<span class="c"># this is an issue as in that case norm.ppf( F_est(t) ) will return Nan</span>
		<span class="c"># so we force F_est(t) to be smaller than 0.999999998 which corresponds to</span>
		<span class="c"># norm.ppf( F_est(t) ) being smaller than 6.3</span>
		<span class="c"># Normally doing this shouldn&#39;t cause any problem. But such extrem t values can</span>
		<span class="c"># be queried by the binomial search to invert the mapping (mapping_inv)</span>
		<span class="k">if</span><span class="p">(</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="mi">2047483647</span><span class="p">):</span>
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
				<span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
				<span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
				<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">):</span>
					<span class="c">## coefficients are :</span>
					<span class="c">#	 exp{  - sum [ (d_i /std_i) **2 ]  }</span>
					<span class="n">coefs</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_latent_mapping</span><span class="o">*</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">centroids</span><span class="p">[</span><span class="n">w</span><span class="p">])</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">clusters_std</span><span class="p">)</span><span class="o">**</span><span class="mf">2.</span> <span class="p">)</span> <span class="p">)</span>
					<span class="n">temp</span>  <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="n">w</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
					<span class="c"># if temp is too close to 1, norm.ppf(temp) == Nan</span>
					<span class="c"># if temp == 0, norm.ppf(temp) == -inf</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
					<span class="k">if</span><span class="p">(</span><span class="n">temp</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
						<span class="n">temp</span> <span class="o">=</span> <span class="mf">1e-10</span>
					<span class="n">val</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span> <span class="p">)</span> 
				
				<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coefs</span><span class="p">)</span>
				<span class="k">if</span><span class="p">(</span><span class="n">s</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
					<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">coefs</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span>
				<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">/</span> <span class="n">s</span>
				<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
				
			<span class="k">else</span><span class="p">:</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
				<span class="c"># if temp is too close to 1, norm.ppf(temp) == Nan</span>
				<span class="c"># if temp == 0, norm.ppf(temp) == -inf</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
				<span class="k">if</span><span class="p">(</span><span class="n">temp</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="mf">1e-10</span>
				<span class="n">v</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">v</span> <span class="o">=</span> <span class="mf">8.3</span>
			
		<span class="k">return</span> <span class="p">[</span><span class="n">v</span><span class="p">]</span>
		

	<span class="k">def</span> <span class="nf">mapping_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
		<span class="k">if</span><span class="p">(</span><span class="n">t</span><span class="o">&lt;=</span> <span class="mf">8.2</span><span class="p">):</span>
			<span class="k">def</span> <span class="nf">map</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
				<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
			<span class="n">lo</span><span class="p">,</span> <span class="n">hi</span> <span class="o">=</span> <span class="n">find_bounds</span><span class="p">(</span><span class="nb">map</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
			<span class="n">res</span> <span class="o">=</span> <span class="n">binary_search</span><span class="p">(</span><span class="nb">map</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">)</span>				
			<span class="k">return</span> <span class="p">[</span><span class="n">res</span><span class="p">]</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="k">return</span> <span class="p">[</span><span class="mi">2047483647</span><span class="p">]</span>


	<span class="k">def</span> <span class="nf">mapping_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
		<span class="c"># our mapping function is constant for t values greater than 2047483646</span>
		<span class="c"># so for such values mapping_derivate should be null</span>
		<span class="k">if</span><span class="p">(</span><span class="n">normalize</span><span class="p">):</span>
			<span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span>
		<span class="n">v</span> <span class="o">=</span> <span class="mf">0.</span>
		<span class="k">if</span><span class="p">(</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="mi">2047483646</span><span class="p">):</span>
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
				<span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
				<span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
				<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">):</span>
					<span class="c">## coefficients are :</span>
					<span class="c">#	 exp{  - sum [ (d_i /std_i) **2 ]  }</span>
					<span class="n">coefs</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_latent_mapping</span><span class="o">*</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">centroids</span><span class="p">[</span><span class="n">w</span><span class="p">])</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">clusters_std</span><span class="p">)</span><span class="o">**</span><span class="mf">2.</span> <span class="p">)</span> <span class="p">)</span>
					<span class="c"># computing Psi_i (t) </span>
					<span class="n">temp</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="n">w</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span> <span class="n">temp</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">)</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
					<span class="c"># pdf( Psi_i (t))</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
					<span class="c"># d_est_i / pdf(...)</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="n">w</span><span class="p">](</span><span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">temp</span>
					<span class="n">val</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span>
				<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coefs</span><span class="p">)</span>
				<span class="k">if</span><span class="p">(</span><span class="n">s</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
					<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">coefs</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span>
				<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">/</span> <span class="n">s</span>
				<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

			<span class="k">else</span><span class="p">:</span>
				<span class="n">temp</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span> <span class="n">temp</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">)</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
				<span class="c"># pdf( Psi (t))</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
				<span class="c"># d_est / pdf(...)</span>
				<span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">temp</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">v</span> <span class="o">=</span> <span class="mf">0.</span>
			
		<span class="k">return</span> <span class="p">(</span><span class="n">v</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span><span class="p">)</span>	


	<span class="k">def</span> <span class="nf">integrate_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">):</span>
		<span class="c"># utility function for the predict method</span>
		<span class="k">def</span> <span class="nf">f_to_integrate</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span> <span class="o">*</span> <span class="p">(</span><span class="n">u</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="p">)</span>
			<span class="k">return</span> <span class="n">temp</span>
		<span class="k">return</span><span class="p">(</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">f_to_integrate</span><span class="p">,</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">,</span><span class="n">epsrel</span> <span class="o">=</span><span class="mf">0.000000001</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>


	<span class="k">def</span> <span class="nf">predicted_RV</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
		<span class="c"># utility function for the predict method</span>
		<span class="k">def</span> <span class="nf">f_to_integrate</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span> <span class="o">*</span> <span class="p">(</span><span class="n">u</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="p">)</span>
			<span class="k">return</span> <span class="n">temp</span>
		<span class="k">return</span> <span class="n">f_to_integrate</span>


	<span class="k">def</span> <span class="nf">init_mappings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
		<span class="c"># We assume y is one-dimensional</span>
	
		<span class="c"># Perform KMeans and store results</span>
		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>

			<span class="n">clustering_pending</span> <span class="o">=</span> <span class="bp">True</span>
			<span class="k">while</span><span class="p">(</span><span class="n">clustering_pending</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span><span class="mi">1</span> <span class="p">):</span>
				<span class="n">clustering_pending</span> <span class="o">=</span> <span class="bp">False</span>
				<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
				<span class="n">all_data</span> <span class="o">=</span> <span class="p">[]</span>
				<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
					<span class="n">all_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
				<span class="n">all_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">all_data</span><span class="p">)</span>
				<span class="n">windows_idx</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">all_data</span><span class="p">)</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">centroids</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
		
				<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
					<span class="k">print</span><span class="p">(</span><span class="s">&#39;All data shape :&#39;</span><span class="p">,</span><span class="n">all_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
					<span class="k">print</span> <span class="p">(</span><span class="s">&quot;Centroids&quot;</span><span class="p">)</span>
					<span class="k">print</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_std</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">centroids</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span><span class="o">*</span><span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span><span class="p">)</span>
				
				<span class="c"># Compute the density function for each sub-window</span>
				<span class="n">density_functions</span> <span class="o">=</span> <span class="p">[]</span>
				<span class="n">clusters_std</span> <span class="o">=</span> <span class="p">[]</span>
				<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
					<span class="n">detailed_windows_idx</span> <span class="o">=</span><span class="n">reshape_cluster_labels</span><span class="p">(</span><span class="n">windows_idx</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span><span class="p">)</span>
				<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">):</span>
					<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
						<span class="n">cluster_points_y_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span><span class="p">[</span> <span class="n">detailed_windows_idx</span> <span class="o">==</span> <span class="n">w</span><span class="p">])[:,</span><span class="mi">0</span><span class="p">])</span>
					<span class="k">else</span><span class="p">:</span>
						<span class="n">cluster_points_y_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[</span> <span class="n">windows_idx</span> <span class="o">==</span> <span class="n">w</span><span class="p">])[:,</span><span class="mi">0</span><span class="p">])</span>
					<span class="n">clusters_std</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span> <span class="n">windows_idx</span> <span class="o">==</span> <span class="n">w</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">)</span> <span class="c">### this is a (Xdim) array</span>
					<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
						<span class="k">print</span><span class="p">(</span><span class="s">&#39;cluster &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="s">&#39; size &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cluster_points_y_values</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
					<span class="k">if</span><span class="p">(</span><span class="n">cluster_points_y_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
						<span class="n">clustering_pending</span> <span class="o">=</span> <span class="bp">True</span>
					<span class="k">else</span><span class="p">:</span>
						<span class="n">density_functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="n">cluster_points_y_values</span><span class="p">)</span> <span class="p">)</span>
				
				<span class="k">if</span><span class="p">(</span><span class="n">clustering_pending</span><span class="p">):</span>
					<span class="k">print</span> <span class="p">(</span><span class="s">&#39;Fail to build &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#39; clusters&#39;</span><span class="p">)</span>
					<span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">-=</span> <span class="mi">1</span>

				<span class="k">else</span><span class="p">:</span>
					<span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="n">density_functions</span><span class="p">)</span>
					<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">density_functions</span>
					<span class="n">clusters_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">clusters_std</span><span class="p">)</span>
					<span class="n">clusters_std</span><span class="p">[</span><span class="n">clusters_std</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
					<span class="bp">self</span><span class="o">.</span><span class="n">clusters_std</span> <span class="o">=</span> <span class="n">clusters_std</span>

					<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
						<span class="k">print</span><span class="p">(</span><span class="s">&#39;---STD---&#39;</span><span class="p">)</span>
						<span class="k">print</span><span class="p">(</span><span class="n">clusters_std</span><span class="p">)</span>	

			<span class="k">if</span><span class="p">(</span><span class="n">clustering_pending</span><span class="p">):</span>
				<span class="c"># n_cluster == 1</span>
				<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
					<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>	

		<span class="k">else</span><span class="p">:</span>
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>
		
		
	<span class="k">def</span> <span class="nf">update_copula_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

		<span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="n">y</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
		<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
		
		<span class="c"># Normalize data</span>
		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reNormalizeY</span><span class="p">):</span>
			<span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">y_std</span><span class="p">[</span><span class="n">y_std</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">y_mean</span> <span class="o">=</span> <span class="mf">0.</span>
			<span class="n">y_std</span> <span class="o">=</span> <span class="mf">1.</span>
		<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_std</span>

		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">obs_noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_noise</span> <span class="o">==</span> <span class="s">&#39;EGN&#39;</span> <span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">*</span><span class="p">(</span> <span class="p">(</span> <span class="mf">10.</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs_noise</span> <span class="p">)</span> <span class="o">**</span> <span class="mf">2.</span> <span class="p">)</span>

		<span class="c"># Calculate matrix of distances D between samples</span>
		<span class="n">D</span><span class="p">,</span> <span class="n">ij</span> <span class="o">=</span> <span class="n">l1_cross_distances</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
		<span class="c">#if (np.min(np.sum(D, axis=1)) == 0.):</span>
		<span class="c">#	raise Exception(&quot;Multiple input features cannot have the same&quot;</span>
		<span class="c">#					&quot; target value.&quot;)</span>

		<span class="n">n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="c"># Regression matrix and parameters</span>
		<span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
		<span class="n">n_samples_F</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
			<span class="n">p</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
		<span class="k">if</span> <span class="n">n_samples_F</span> <span class="o">!=</span> <span class="n">n_samples</span><span class="p">:</span>
			<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Number of rows in F and X do not match. Most &quot;</span>
							<span class="s">&quot;likely something is going wrong with the &quot;</span>
							<span class="s">&quot;regression model.&quot;</span><span class="p">)</span>
		<span class="k">if</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="n">n_samples_F</span><span class="p">:</span>
			<span class="k">raise</span> <span class="ne">Exception</span><span class="p">((</span><span class="s">&quot;Ordinary least squares problem is undetermined &quot;</span>
							 <span class="s">&quot;n_samples=</span><span class="si">%d</span><span class="s"> must be greater than the &quot;</span>
							 <span class="s">&quot;regression model size p=</span><span class="si">%d</span><span class="s">.&quot;</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">D</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">ij</span> <span class="o">=</span> <span class="n">ij</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">F</span> <span class="o">=</span> <span class="n">F</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">=</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span>
			
			
	<span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">detailed_y_obs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">obs_noise</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		The Gaussian Copula Process model fitting method.</span>

<span class="sd">		Parameters</span>
<span class="sd">		----------</span>
<span class="sd">		`X` : double array_like  </span>
<span class="sd">			An array with shape (n_samples, n_features) with the input at which</span>
<span class="sd">			observations were made.  </span>

<span class="sd">		`y` : double array_like  </span>
<span class="sd">			An array with shape (n_samples, ) or shape (n_samples, n_targets)</span>
<span class="sd">			with the observations of the output to be predicted.</span>
<span class="sd">			Currently only 1D targets are supported.  </span>

<span class="sd">		`detailed_y_obs` : double list of list  </span>
<span class="sd">			A list of length n_samples where entry at position i corresponds to </span>
<span class="sd">			the mutiple noisy observations (given as a list) of the input value X[i,:], </span>
<span class="sd">			and whose mean is y[i].  </span>
<span class="sd">			If not None, it can be used to learn the mapping function or fit the GP,</span>
<span class="sd">			see parameters mapWithNoise and useAllNoisyY of the GaussianCopulaProcess class.  </span>

<span class="sd">		`obs_noise` : double array  </span>
<span class="sd">			An array of shape (n_samples,) corresponding to the estimated noise</span>
<span class="sd">			in the observed y outputs.  </span>
<span class="sd">			If not None, it can be used to model the noise with the Estimated</span>
<span class="sd">			Gaussian Noise method, see the model_noise parameter of the </span>
<span class="sd">			GaussianCopulaProcess class.  </span>

<span class="sd">		Returns</span>
<span class="sd">		-------</span>
<span class="sd">		`gcp` : self  </span>
<span class="sd">			A fitted Gaussian Copula Process model object awaiting data to perform</span>
<span class="sd">			predictions.  </span>
<span class="sd">		&quot;&quot;&quot;</span>
		<span class="c"># Run input checks</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">()</span>
		<span class="n">X</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">array2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
		<span class="c"># Check if all CV obs are given</span>
		<span class="c"># and if so, convert this list of list to array</span>
		<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
			<span class="n">detailed_X</span><span class="p">,</span><span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="n">listOfList_toArray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">detailed_y_obs</span><span class="p">)</span>	

		<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">y_ndim_</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span>
		<span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
			<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
			<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
				<span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="n">detailed_raw_y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="k">print</span><span class="p">(</span><span class="s">&#39;Warning: code is not ready for y outputs with dimension &gt; 1&#39;</span><span class="p">)</span>
		
		<span class="c"># Reshape theta if it is one dimensional and X is not</span>
		<span class="n">x_dim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
		<span class="c">#if not(self.theta.ndim == 1):</span>
		<span class="c">#	print(&#39;Warning : theta has not the right shape&#39;)</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x_dim</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="p">)</span><span class="o">.</span><span class="n">T</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x_dim</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="p">)</span><span class="o">.</span><span class="n">T</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x_dim</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="p">)</span><span class="o">.</span><span class="n">T</span>
		<span class="c">#print(&#39;theta has new shape &#39;+str(self.theta.shape))</span>
			
		<span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>		
		<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">check_arrays</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

		<span class="c"># Check shapes of DOE &amp; observations</span>
		<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
		<span class="n">_</span><span class="p">,</span> <span class="n">n_targets</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>

		<span class="c"># Run input checks</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

		<span class="c"># Normalize data or don&#39;t</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
			<span class="n">X_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">X_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">X_std</span><span class="p">[</span><span class="n">X_std</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
			<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_std</span>

			<span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
			<span class="n">raw_y_std</span><span class="p">[</span><span class="n">raw_y_std</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
			<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">raw_y_std</span>
			
			<span class="k">if</span><span class="p">(</span><span class="n">obs_noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
				<span class="n">obs_noise</span> <span class="o">=</span> <span class="n">obs_noise</span> <span class="o">/</span> <span class="n">raw_y_std</span>

			<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
				<span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">detailed_raw_y</span> <span class="o">-</span> <span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">raw_y_std</span>
				<span class="n">detailed_X</span> <span class="o">=</span> <span class="p">(</span><span class="n">detailed_X</span> <span class="o">-</span> <span class="n">X_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_std</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">X_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
			<span class="n">X_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
		
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>		
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

		<span class="c"># Set attributes</span>

		<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="n">detailed_raw_y</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span> <span class="o">=</span> <span class="n">detailed_X</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="bp">None</span>			
			<span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span> <span class="o">=</span> <span class="bp">None</span>			
		
		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span>
			
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">raw_y_mean</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">raw_y_std</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="o">-</span><span class="mf">500.</span><span class="p">,</span> <span class="mf">5.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)])</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span> <span class="o">=</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">X_std</span>

			<span class="c"># initialize mapping only if needed, i.e. it hasn&#39;t be done </span>
			<span class="c"># yet of if we want to optimize the GCP hyperparameters</span>
			<span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)):</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">init_mappings</span><span class="p">()</span>
		
		<span class="k">elif</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="n">y</span>

			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">raw_y_mean</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">raw_y_std</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="o">-</span><span class="mf">500.</span><span class="p">,</span> <span class="mf">5.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)])</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span> <span class="o">=</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">X_std</span>

			<span class="c"># initialize mapping only if needed, i.e. it hasn&#39;t be done </span>
			<span class="c"># yet of if we want to optimize the GCP hyperparameters</span>
			<span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)):</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">init_mappings</span><span class="p">()</span>

			<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span>

		<span class="k">else</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="n">y</span>

			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">raw_y_mean</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">raw_y_std</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="o">-</span><span class="mf">500.</span><span class="p">,</span> <span class="mf">5.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)])</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span> <span class="o">=</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">X_std</span>

			<span class="c"># initialize mapping only if needed, i.e. it hasn&#39;t be done </span>
			<span class="c"># yet of if we want to optimize the GCP hyperparameters</span>
			<span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)):</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">init_mappings</span><span class="p">()</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">obs_noise</span> <span class="o">=</span> <span class="n">obs_noise</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">update_copula_params</span><span class="p">()</span>
		
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span><span class="p">:</span>
		    <span class="c"># Maximum Likelihood Estimation of the parameters</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
				<span class="k">print</span><span class="p">(</span><span class="s">&quot;Performing Maximum Likelihood Estimation of the &quot;</span>
					  <span class="s">&quot;autocorrelation parameters...&quot;</span><span class="p">)</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">,</span> <span class="n">par</span> <span class="o">=</span> \
				<span class="bp">self</span><span class="o">.</span><span class="n">_arg_max_reduced_likelihood_function</span><span class="p">()</span>
			<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">):</span>
				<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Bad parameter region. &quot;</span>
								<span class="s">&quot;Try increasing upper bound&quot;</span><span class="p">)</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="c"># Given parameters</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
				<span class="k">print</span><span class="p">(</span><span class="s">&quot;Given autocorrelation parameters. &quot;</span>
					  <span class="s">&quot;Computing Gaussian Process model parameters...&quot;</span><span class="p">)</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">,</span> <span class="n">par</span> <span class="o">=</span> \
				<span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">()</span>
			<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">):</span>
				<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Bad point. Try increasing theta0.&quot;</span><span class="p">)</span>

		<span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;beta&#39;</span><span class="p">]</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;gamma&#39;</span><span class="p">]</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;sigma2&#39;</span><span class="p">]</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;C&#39;</span><span class="p">]</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">Ft</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;Ft&#39;</span><span class="p">]</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;G&#39;</span><span class="p">]</span>

		<span class="k">return</span> <span class="bp">self</span>

	<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">eval_MSE</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transformY</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">returnRV</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">integratedPrediction</span><span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">eval_confidence_bounds</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">coef_bound</span><span class="o">=</span><span class="mf">1.96</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		This function evaluates the Gaussian Process model at x.  </span>

<span class="sd">		Parameters</span>
<span class="sd">		----------</span>
<span class="sd">		`X` : array_like  </span>
<span class="sd">			An array with shape (n_eval, n_features) giving the point(s) at</span>
<span class="sd">			which the prediction(s) should be made.  </span>

<span class="sd">		`eval_MSE` : boolean, optional  </span>
<span class="sd">			A boolean specifying whether the Mean Squared Error should be</span>
<span class="sd">			evaluated or not.  </span>
<span class="sd">			Default assumes evalMSE = False and evaluates only the BLUP (mean</span>
<span class="sd">			prediction).  </span>

<span class="sd">		`transformY` : boolean, optional  </span>
<span class="sd">			A boolean specifying if the predicted values should correspond to</span>
<span class="sd">			the same space as the data given to the fit method, or to the</span>
<span class="sd">			warped space (in which the GP is fitted).</span>
<span class="sd">			Default is True. Setting to False can be useful to compute the Expected</span>
<span class="sd">			Improvement in an optimization process.  </span>

<span class="sd">		`returnRV` : boolean, optional  </span>
<span class="sd">			A boolean specifying if the method should return the predicted random variables</span>
<span class="sd">			at x instead of a float number.  </span>
<span class="sd">			Default is False.  </span>

<span class="sd">		`integratedPrediction` : boolean, optional  </span>
<span class="sd">			A boolean specifying if the method should return the fully Bayesian</span>
<span class="sd">			prediction, ie compute the expectation given the posterior in the</span>
<span class="sd">			original space. If False, the returned value is the inverse value</span>
<span class="sd">			(by the mapping function) of the GP prediction. This is much more faster</span>
<span class="sd">			as the integratedPrediction needs to numerically compute the integral.</span>
<span class="sd">			Default is False.  </span>

<span class="sd">		`eval_confidence_bounds` : boolean, optional  </span>
<span class="sd">			A boolean specifying if the method should return the confidence bounds.</span>
<span class="sd">			Because of the non-linearity of the mapping function, this cannot be computed</span>
<span class="sd">			directly with the MSE, but needs to invert the mapping function.  </span>
<span class="sd">			Default is False. If True, coef_bound specifies the boundary to compute.  </span>

<span class="sd">		`coef_bound` : float, optional  </span>
<span class="sd">			A float specifying the confidence bounds to compute. Upper and lower</span>
<span class="sd">			confidence bounds are computed as the inverse of m + coef_bound*sigma</span>
<span class="sd">			where m and sigma are the mean and the std of the posterior in the GP</span>
<span class="sd">			space.  </span>
<span class="sd">			Default is 1.96 which corresponds to the 95% confidence bounds.  </span>

<span class="sd">		`batch_size` : integer, optional  </span>
<span class="sd">			An integer giving the maximum number of points that can be</span>
<span class="sd">			evaluated simultaneously (depending on the available memory).</span>
<span class="sd">			Default is None so that all given points are evaluated at the same</span>
<span class="sd">			time.  </span>

<span class="sd">		Returns</span>
<span class="sd">		-------</span>
<span class="sd">		`y` : array_like, shape (n_samples,)  </span>
<span class="sd">			Prediction at x.</span>

<span class="sd">		`MSE` : array_like, optional (if eval_MSE == True)  </span>
<span class="sd">			Mean Squared Error at x.</span>

<span class="sd">		`LCB` : array_like, optional (if eval_confidence_bounds == True)  </span>
<span class="sd">			Lower confidence bound.</span>

<span class="sd">		`UCB` : array_like, optional (if eval_confidence_bounds == True)  </span>
<span class="sd">			Upper confidence bound.</span>
<span class="sd">		&quot;&quot;&quot;</span>

		<span class="c"># Check input shapes</span>
		<span class="n">X</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">array2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
		<span class="n">n_eval</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
		<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span>
		<span class="n">n_samples_y</span><span class="p">,</span> <span class="n">n_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span>

		<span class="k">if</span><span class="p">(</span><span class="n">n_targets</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
			<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&#39;More than one target in the Y outputs. </span><span class="se">\</span>
<span class="s">							  Currently only 1D outputs are handled&#39;</span><span class="p">)</span>

		<span class="c"># Run input checks</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

		<span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">n_features</span><span class="p">:</span>
			<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s">&quot;The number of features in X (X.shape[1] = </span><span class="si">%d</span><span class="s">) &quot;</span>
							  <span class="s">&quot;should match the number of features used &quot;</span>
							  <span class="s">&quot;for fit() &quot;</span>
							  <span class="s">&quot;which is </span><span class="si">%d</span><span class="s">.&quot;</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_features</span><span class="p">))</span>

		<span class="c"># Normalize input</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
			<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span>
			
		<span class="c"># Initialize output</span>
		<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_eval</span><span class="p">)</span>
		<span class="k">if</span> <span class="n">eval_MSE</span><span class="p">:</span>
			<span class="n">MSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_eval</span><span class="p">)</span>

		<span class="c"># Get pairwise componentwise L1-distances to the input training set</span>
		<span class="n">dx</span> <span class="o">=</span> <span class="n">manhattan_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">sum_over_features</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
		<span class="c"># Get regression function and correlation</span>
		<span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
		<span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">dx</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>

		<span class="c"># Scaled predictor</span>
		<span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>

		<span class="c"># Predictor</span>
		<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">*</span> <span class="n">y_</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span>

		<span class="c"># transform the warped y, modeled as a Gaussian, to the real y</span>
		<span class="n">size</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="n">warped_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
		
		<span class="k">if</span><span class="p">(</span><span class="n">transformY</span><span class="p">):</span>
			<span class="k">if</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">8.2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)])</span> <span class="o">&gt;</span><span class="mi">0</span><span class="p">):</span>
				<span class="k">print</span><span class="p">(</span><span class="s">&#39;Warning : mapping_inversion failed&#39;</span><span class="p">)</span>
			<span class="n">real_y</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_inv</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
			<span class="n">real_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">real_y</span><span class="p">)</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span>
			<span class="n">y</span> <span class="o">=</span> <span class="n">real_y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span>
		
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_ndim_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
			<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
			<span class="n">warped_y</span> <span class="o">=</span> <span class="n">warped_y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

		<span class="c"># Mean Squared Error</span>
		<span class="k">if</span> <span class="n">eval_MSE</span><span class="p">:</span>
			<span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span>
			<span class="k">if</span> <span class="n">C</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
				<span class="c"># Light storage mode (need to recompute C, F, Ft and G)</span>
				<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
					<span class="k">print</span><span class="p">(</span><span class="s">&quot;This GaussianProcess used &#39;light&#39; storage mode &quot;</span>
						  <span class="s">&quot;at instantiation. Need to recompute &quot;</span>
						  <span class="s">&quot;autocorrelation matrix...&quot;</span><span class="p">)</span>
				<span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span> <span class="o">=</span> \
					<span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">()</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;C&#39;</span><span class="p">]</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">Ft</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;Ft&#39;</span><span class="p">]</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;G&#39;</span><span class="p">]</span>

			<span class="n">rt</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta0</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
				<span class="c"># Universal Kriging</span>
				<span class="n">u</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
											<span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Ft</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rt</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="c"># Ordinary Kriging</span>
				<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_targets</span><span class="p">,</span> <span class="n">n_eval</span><span class="p">))</span>

			<span class="n">MSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_targets</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
						 <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="p">(</span><span class="n">rt</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
						  <span class="o">+</span> <span class="p">(</span><span class="n">u</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:])</span>
			<span class="n">MSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">MSE</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_targets</span><span class="p">)</span>

			<span class="c"># Mean Squared Error might be slightly negative depending on</span>
			<span class="c"># machine precision: force to zero!</span>
			<span class="n">MSE</span><span class="p">[</span><span class="n">MSE</span> <span class="o">&lt;</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>

			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_ndim_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
				<span class="n">MSE</span> <span class="o">=</span> <span class="n">MSE</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
				<span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">MSE</span><span class="p">)</span>
				<span class="k">if</span><span class="p">(</span><span class="n">returnRV</span><span class="p">):</span>
					<span class="k">return</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">predicted_RV</span><span class="p">([</span><span class="n">warped_y</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="k">if</span><span class="p">(</span><span class="n">eval_confidence_bounds</span><span class="p">):</span>
						<span class="k">if</span> <span class="ow">not</span><span class="p">(</span><span class="n">transformY</span><span class="p">):</span>
							<span class="k">print</span><span class="p">(</span><span class="s">&#39;Warning, transformY set to False but trying to evaluate conf bounds&#39;</span><span class="p">)</span>
						<span class="n">warped_y_with_boundL</span> <span class="o">=</span> <span class="n">warped_y</span> <span class="o">-</span> <span class="n">coef_bound</span> <span class="o">*</span> <span class="n">sigma</span>
						<span class="n">warped_y_with_boundU</span> <span class="o">=</span> <span class="n">warped_y</span> <span class="o">+</span> <span class="n">coef_bound</span> <span class="o">*</span> <span class="n">sigma</span>
						<span class="n">pred_with_boundL</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_inv</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">warped_y_with_boundL</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="p">]</span> <span class="p">)</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span>
						<span class="n">pred_with_boundU</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_inv</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">warped_y_with_boundU</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span> <span class="p">)</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span>
						
						<span class="k">if</span><span class="p">(</span><span class="n">integratedPrediction</span><span class="p">):</span>
							<span class="n">lb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span> <span class="o">-</span> <span class="mf">3.</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span><span class="p">)</span>
							<span class="n">ub</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span> <span class="o">+</span> <span class="mf">3.</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span><span class="p">)</span>
							<span class="k">print</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">)</span>
							<span class="n">integrated_real_y</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">integrate_prediction</span><span class="p">([</span><span class="n">warped_y</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
							<span class="n">integrated_real_y</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">integrated_real_y</span><span class="p">)</span>
							<span class="k">print</span><span class="p">(</span><span class="s">&#39;Integrated prediction&#39;</span><span class="p">)</span>
							<span class="k">return</span> <span class="n">integrated_real_y</span><span class="p">,</span><span class="n">MSE</span><span class="p">,</span><span class="n">pred_with_boundL</span><span class="p">,</span><span class="n">pred_with_boundU</span>

						<span class="k">else</span><span class="p">:</span>
							<span class="k">return</span> <span class="n">y</span><span class="p">,</span><span class="n">MSE</span><span class="p">,</span><span class="n">pred_with_boundL</span><span class="p">,</span><span class="n">pred_with_boundU</span>

						
					<span class="k">else</span><span class="p">:</span>
						<span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">MSE</span>
			
			<span class="k">else</span><span class="p">:</span>
				<span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">MSE</span>

		<span class="k">else</span><span class="p">:</span>
			<span class="k">return</span> <span class="n">y</span>


	<span class="k">def</span> <span class="nf">reduced_likelihood_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		This function determines the BLUP parameters and evaluates the reduced</span>
<span class="sd">		likelihood function for the given autocorrelation parameters theta.</span>

<span class="sd">		Maximizing this function wrt the autocorrelation parameters theta is</span>
<span class="sd">		equivalent to maximizing the likelihood of the assumed joint Gaussian</span>
<span class="sd">		distribution of the observations y evaluated onto the design of</span>
<span class="sd">		experiments X.</span>

<span class="sd">		Parameters</span>
<span class="sd">		----------</span>
<span class="sd">		`theta` : array_like, optional</span>
<span class="sd">			An array containing the autocorrelation parameters at which the</span>
<span class="sd">			Gaussian Process model parameters should be determined.</span>
<span class="sd">			Default uses the built-in autocorrelation parameters</span>
<span class="sd">			(ie ``theta = self.theta_``).</span>

<span class="sd">		Returns</span>
<span class="sd">		-------</span>
<span class="sd">		`reduced_likelihood_function_value` : double</span>
<span class="sd">			The value of the reduced likelihood function associated to the</span>
<span class="sd">			given autocorrelation parameters theta.</span>

<span class="sd">		`par` : dict</span>
<span class="sd">			A dictionary containing the requested Gaussian Process model</span>
<span class="sd">			parameters:</span>

<span class="sd">				sigma2</span>
<span class="sd">						Gaussian Process variance.</span>
<span class="sd">				beta</span>
<span class="sd">						Generalized least-squares regression weights for</span>
<span class="sd">						Universal Kriging or given beta0 for Ordinary</span>
<span class="sd">						Kriging.</span>
<span class="sd">				gamma</span>
<span class="sd">						Gaussian Process weights.</span>
<span class="sd">				C</span>
<span class="sd">						Cholesky decomposition of the correlation matrix [R].</span>
<span class="sd">				Ft</span>
<span class="sd">						Solution of the linear equation system : [R] x Ft = F</span>
<span class="sd">				G</span>
<span class="sd">						QR decomposition of the matrix Ft.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		
		<span class="k">if</span> <span class="n">theta</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
			<span class="c"># Use built-in autocorrelation parameters</span>
			<span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span>

		<span class="c"># Initialize output</span>
		<span class="n">reduced_likelihood_function_value</span> <span class="o">=</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
		<span class="n">par</span> <span class="o">=</span> <span class="p">{}</span>

		<span class="c"># Retrieve data</span>
		<span class="n">n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="n">D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span>
		<span class="n">ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ij</span>
		<span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span>

		<span class="k">if</span> <span class="n">D</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
			<span class="c"># Light storage mode (need to recompute D, ij and F)</span>
			<span class="n">D</span><span class="p">,</span> <span class="n">ij</span> <span class="o">=</span> <span class="n">l1_cross_distances</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
			<span class="c">#if (np.min(np.sum(D, axis=1)) == 0.):</span>
			<span class="c">#	raise Exception(&quot;Multiple X are not allowed&quot;)</span>
			<span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

		<span class="c"># Set up R</span>
		<span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
		<span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="p">)</span>
		<span class="n">R</span><span class="p">[</span><span class="n">ij</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ij</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">r</span>
		<span class="n">R</span><span class="p">[</span><span class="n">ij</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ij</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">r</span>

		<span class="c"># Cholesky decomposition of R</span>
		<span class="k">try</span><span class="p">:</span>
			<span class="n">C</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
		<span class="k">except</span> <span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
			<span class="k">return</span> <span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span>

		<span class="c"># Get generalized least squares solution</span>
		<span class="n">Ft</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
		<span class="k">try</span><span class="p">:</span>
			<span class="n">Q</span><span class="p">,</span> <span class="n">G</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
		<span class="k">except</span><span class="p">:</span>
			<span class="c">#/usr/lib/python2.6/dist-packages/scipy/linalg/decomp.py:1177:</span>
			<span class="c"># DeprecationWarning: qr econ argument will be removed after scipy</span>
			<span class="c"># 0.7. The economy transform will then be available through the</span>
			<span class="c"># mode=&#39;economic&#39; argument.</span>
			<span class="n">Q</span><span class="p">,</span> <span class="n">G</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;economic&#39;</span><span class="p">)</span>
			<span class="k">pass</span>

		<span class="n">sv</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
		<span class="n">rcondG</span> <span class="o">=</span> <span class="n">sv</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">sv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
		<span class="k">if</span> <span class="n">rcondG</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
			<span class="c"># Check F</span>
			<span class="n">sv</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
			<span class="n">condF</span> <span class="o">=</span> <span class="n">sv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">sv</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
			<span class="k">if</span> <span class="n">condF</span> <span class="o">&gt;</span> <span class="mf">1e15</span><span class="p">:</span>
				<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;F is too ill conditioned. Poor combination &quot;</span>
								<span class="s">&quot;of regression model and observations.&quot;</span><span class="p">)</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="c"># Ft is too ill conditioned, get out (try different theta)</span>
				<span class="k">return</span> <span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span>

		<span class="n">Yt</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta0</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
			<span class="c"># Universal Kriging</span>
			<span class="n">beta</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Yt</span><span class="p">))</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="c"># Ordinary Kriging</span>
			<span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta0</span><span class="p">)</span>

		<span class="n">rho</span> <span class="o">=</span> <span class="n">Yt</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
		<span class="n">sigma2</span> <span class="o">=</span> <span class="p">(</span><span class="n">rho</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_samples</span>
		<span class="c"># The determinant of R is equal to the squared product of the diagonal</span>
		<span class="c"># elements of its Cholesky decomposition C</span>
		<span class="n">detR</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">C</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">/</span> <span class="n">n_samples</span><span class="p">))</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>

		<span class="c"># Compute/Organize output</span>
		<span class="n">reduced_likelihood_function_value</span> <span class="o">=</span> <span class="o">-</span> <span class="n">sigma2</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="n">detR</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;sigma2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">**</span> <span class="mf">2.</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;beta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;gamma&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rho</span><span class="p">)</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;C&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">C</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;Ft&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Ft</span>
		<span class="n">par</span><span class="p">[</span><span class="s">&#39;G&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">G</span>

		<span class="k">return</span> <span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span>

	<span class="k">def</span> <span class="nf">_arg_max_reduced_likelihood_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
		<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		This function estimates the autocorrelation parameters theta as the</span>
<span class="sd">		maximizer of the reduced likelihood function.</span>
<span class="sd">		(Minimization of the opposite reduced likelihood function is used for</span>
<span class="sd">		convenience)</span>

<span class="sd">		Parameters</span>
<span class="sd">		----------</span>
<span class="sd">		`self` : All parameters are stored in the Gaussian Process model object.</span>

<span class="sd">		Returns</span>
<span class="sd">		-------</span>
<span class="sd">		`optimal_theta` : array_like</span>
<span class="sd">			The best set of autocorrelation parameters (the sought maximizer of</span>
<span class="sd">			the reduced likelihood function).</span>

<span class="sd">		`optimal_reduced_likelihood_function_value` : double</span>
<span class="sd">			The optimal reduced likelihood function value.</span>

<span class="sd">		`optimal_par` : dict</span>
<span class="sd">			The BLUP parameters associated to thetaOpt.</span>
<span class="sd">		&quot;&quot;&quot;</span>
		
		<span class="c"># Initialize output</span>
		<span class="n">best_optimal_theta</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="n">best_optimal_rlf_value</span> <span class="o">=</span> <span class="p">[]</span>
		<span class="n">best_optimal_par</span> <span class="o">=</span> <span class="p">[]</span>

		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
			<span class="k">print</span><span class="p">(</span><span class="s">&quot;The chosen optimizer is: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">))</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_start</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
				<span class="k">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_start</span><span class="p">)</span> <span class="o">+</span> <span class="s">&quot; random starts are required.&quot;</span><span class="p">)</span>

		<span class="n">percent_completed</span> <span class="o">=</span> <span class="mf">0.</span>

		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="s">&#39;fmin_cobyla&#39;</span><span class="p">:</span>

			<span class="k">def</span> <span class="nf">minus_reduced_likelihood_function</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
				<span class="n">x_reshaped</span> <span class="o">=</span> <span class="n">theta_backToRealShape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
				<span class="k">return</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">(</span>
					<span class="n">theta</span><span class="o">=</span><span class="mf">10.</span> <span class="o">**</span> <span class="n">x_reshaped</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
						
			<span class="n">constraints</span> <span class="o">=</span> <span class="p">[]</span>
			<span class="c"># http://stackoverflow.com/questions/25985868/scipy-why-isnt-cobyla-respecting-constraint</span>
			
			<span class="c"># Cobyla takes only one dimensional array</span>
			<span class="n">conL</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">theta_toOneDim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">))</span>
			<span class="n">conU</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">theta_toOneDim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">))</span>
			
			<span class="k">def</span> <span class="nf">kernel_coef</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
				<span class="k">return</span><span class="p">(</span><span class="mf">100.</span> <span class="o">-</span> <span class="p">((</span><span class="mf">10.</span> <span class="o">**</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="mf">10.</span> <span class="o">**</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="mf">10.</span> <span class="o">**</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="p">))</span>
			
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
				<span class="n">n_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>	
			<span class="k">else</span><span class="p">:</span>
				<span class="n">n_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">size</span>
			<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_idx</span><span class="p">):</span>
				<span class="n">lower</span> <span class="o">=</span> <span class="n">conL</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
				<span class="n">upper</span> <span class="o">=</span> <span class="n">conU</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
				<span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">lower</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">idx</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span>
				<span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">upper</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">idx</span><span class="p">:</span> <span class="n">b</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
			
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
				<span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kernel_coef</span><span class="p">)</span>
			
			<span class="n">k</span><span class="o">=</span><span class="mi">0</span>
			<span class="n">k2</span> <span class="o">=</span> <span class="mi">0</span>
			<span class="k">while</span><span class="p">(</span> <span class="p">(</span><span class="n">k</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_start</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">k2</span> <span class="o">&lt;</span> <span class="mi">50</span><span class="p">)):</span>
					
				<span class="k">if</span> <span class="p">(</span><span class="n">k</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">k2</span> <span class="o">==</span><span class="mi">0</span><span class="p">):</span>
					<span class="c"># Use specified starting point as first guess</span>
					<span class="n">theta0</span> <span class="o">=</span> <span class="n">theta_toOneDim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)</span>

				<span class="k">else</span><span class="p">:</span>
					<span class="c"># Generate a random starting point log10-uniformly</span>
					<span class="c"># distributed between bounds</span>
					<span class="n">log10theta0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">)</span> \
						<span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
							<span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span>
														  <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">)</span>
					<span class="n">theta0</span> <span class="o">=</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">theta_toOneDim</span><span class="p">(</span><span class="n">log10theta0</span><span class="p">)</span>
					
				<span class="c"># Run Cobyla</span>
				<span class="k">try</span><span class="p">:</span>
					<span class="n">params</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">theta0</span><span class="p">)</span>
					<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
						<span class="k">print</span><span class="p">(</span><span class="s">&#39;try &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
						
					<span class="n">log10_opt</span> <span class="o">=</span> \
						<span class="n">optimize</span><span class="o">.</span><span class="n">fmin_cobyla</span><span class="p">(</span><span class="n">minus_reduced_likelihood_function</span><span class="p">,</span>
											 <span class="n">params</span><span class="p">,</span>
											 <span class="n">constraints</span><span class="p">,</span>
											 <span class="n">maxfun</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span>
											 <span class="c">#rhobeg=2.0,</span>
											 <span class="n">rhoend</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
											 <span class="n">iprint</span><span class="o">=</span><span class="mi">0</span>
											 <span class="p">)</span>
					<span class="n">opt_minus_rlf</span> <span class="o">=</span> <span class="n">minus_reduced_likelihood_function</span><span class="p">(</span><span class="n">log10_opt</span><span class="p">)</span>
					<span class="c">#print(opt_minus_rlf)</span>
					<span class="n">log10_optimal_theta</span> <span class="o">=</span> <span class="n">theta_backToRealShape</span><span class="p">(</span><span class="n">log10_opt</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
					
				<span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">ve</span><span class="p">:</span>
					<span class="n">opt_minus_rlf</span> <span class="o">=</span> <span class="mf">999999999.</span>
					<span class="n">k2</span> <span class="o">+=</span> <span class="mi">1</span>
					<span class="k">raise</span> <span class="n">ve</span>
					<span class="k">print</span><span class="p">(</span><span class="s">&#39;Warning, exception raised in Cobyla&#39;</span><span class="p">)</span>
				
				<span class="k">if</span><span class="p">(</span><span class="n">opt_minus_rlf</span> <span class="o">!=</span> <span class="mf">999999999.</span> <span class="p">):</span>
				
					<span class="n">optimal_theta</span> <span class="o">=</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">log10_optimal_theta</span>
					<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
						<span class="k">print</span><span class="p">(</span><span class="n">optimal_theta</span><span class="p">)</span>
					<span class="n">optimal_rlf_value</span><span class="p">,</span> <span class="n">optimal_par</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">optimal_theta</span><span class="p">)</span>

					<span class="c"># Compare the new optimizer to the best previous one</span>
					<span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
						<span class="k">if</span> <span class="n">optimal_rlf_value</span> <span class="o">&gt;</span> <span class="n">best_optimal_rlf_value</span><span class="p">:</span>
							<span class="n">best_optimal_rlf_value</span> <span class="o">=</span> <span class="n">optimal_rlf_value</span>
							<span class="n">best_optimal_par</span> <span class="o">=</span> <span class="n">optimal_par</span>
							<span class="n">best_optimal_theta</span> <span class="o">=</span> <span class="n">optimal_theta</span>
					<span class="k">else</span><span class="p">:</span>
						<span class="n">best_optimal_rlf_value</span> <span class="o">=</span> <span class="n">optimal_rlf_value</span>
						<span class="n">best_optimal_par</span> <span class="o">=</span> <span class="n">optimal_par</span>
						<span class="n">best_optimal_theta</span> <span class="o">=</span> <span class="n">optimal_theta</span>
					<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_start</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
						<span class="k">if</span> <span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="n">k</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_start</span> <span class="o">&gt;</span> <span class="n">percent_completed</span><span class="p">:</span>
							<span class="n">percent_completed</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="n">k</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_start</span>
							<span class="k">print</span><span class="p">(</span><span class="s">&quot;</span><span class="si">%s</span><span class="s"> completed&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">5</span> <span class="o">*</span> <span class="n">percent_completed</span><span class="p">))</span>
					
					<span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>
					
				<span class="k">else</span><span class="p">:</span>
					<span class="n">k2</span> <span class="o">+=</span> <span class="mi">1</span>
					<span class="k">if</span><span class="p">(</span><span class="n">k2</span> <span class="o">==</span> <span class="mi">50</span> <span class="ow">and</span> <span class="n">k</span><span class="o">==</span><span class="mi">0</span><span class="p">):</span>
						<span class="k">print</span><span class="p">(</span><span class="s">&quot;Cobyla Optimization failed. Try increasing the ``nugget``&quot;</span><span class="p">)</span>
						<span class="n">best_optimal_theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span>
						<span class="n">best_optimal_rlf_value</span><span class="p">,</span> <span class="n">best_optimal_par</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">best_optimal_theta</span><span class="p">)</span>
									
			<span class="n">optimal_rlf_value</span> <span class="o">=</span> <span class="n">best_optimal_rlf_value</span>
			<span class="n">optimal_par</span> <span class="o">=</span> <span class="n">best_optimal_par</span>
			<span class="n">optimal_theta</span> <span class="o">=</span> <span class="n">best_optimal_theta</span>
			
		<span class="k">else</span><span class="p">:</span>
			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s">&quot;This optimizer (&#39;</span><span class="si">%s</span><span class="s">&#39;) is not &quot;</span>
									  <span class="s">&quot;implemented yet. Please contribute!&quot;</span>
									  <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>

		<span class="k">return</span> <span class="n">optimal_theta</span><span class="p">,</span> <span class="n">optimal_rlf_value</span><span class="p">,</span> <span class="n">optimal_par</span>


	<span class="k">def</span> <span class="nf">_check_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

		<span class="c"># Check regression model</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">):</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="p">:</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">regr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">]</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;regr should be one of </span><span class="si">%s</span><span class="s"> or callable, &quot;</span>
								 <span class="s">&quot;</span><span class="si">%s</span><span class="s"> was given.&quot;</span>
								 <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">))</span>

		<span class="c"># Check correlation model</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">):</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_correlation_types</span><span class="p">:</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_correlation_types</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">]</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;corr should be one of </span><span class="si">%s</span><span class="s"> or callable, &quot;</span>
								 <span class="s">&quot;</span><span class="si">%s</span><span class="s"> was given.&quot;</span>
								 <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_correlation_types</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">))</span>


		<span class="c"># Force verbose type to bool</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

		<span class="c"># Force normalize type to bool</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">)</span>

		<span class="c"># Check nugget value</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="p">)</span>
		<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.</span><span class="p">:</span>
			<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;nugget must be positive or zero.&quot;</span><span class="p">)</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">n_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
				<span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="o">.</span><span class="n">shape</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[(),</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,)]):</span>
			<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;nugget must be either a scalar &quot;</span>
							 <span class="s">&quot;or array of length n_samples.&quot;</span><span class="p">)</span>


		<span class="c"># Force random_start type to int</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">random_start</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_start</span><span class="p">)</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#gcp_hpo.gcp.gcp.GaussianCopulaProcess">GaussianCopulaProcess</a></li>
          <li>sklearn.base.BaseEstimator</li>
          <li>sklearn.base.RegressorMixin</li>
          <li>__builtin__.object</li>
          </ul>
          <h3>Instance variables</h3>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.beta0" class="name">var <span class="ident">beta0</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.coef_latent_mapping" class="name">var <span class="ident">coef_latent_mapping</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.density_functions" class="name">var <span class="ident">density_functions</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapWithNoise" class="name">var <span class="ident">mapWithNoise</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.model_noise" class="name">var <span class="ident">model_noise</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.n_clusters" class="name">var <span class="ident">n_clusters</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.normalize" class="name">var <span class="ident">normalize</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.nugget" class="name">var <span class="ident">nugget</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.optimizer" class="name">var <span class="ident">optimizer</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.random_start" class="name">var <span class="ident">random_start</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.random_state" class="name">var <span class="ident">random_state</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.reNormalizeY" class="name">var <span class="ident">reNormalizeY</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.regr" class="name">var <span class="ident">regr</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.theta" class="name">var <span class="ident">theta</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.thetaL" class="name">var <span class="ident">thetaL</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.thetaU" class="name">var <span class="ident">thetaU</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.try_optimize" class="name">var <span class="ident">try_optimize</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.useAllNoisyY" class="name">var <span class="ident">useAllNoisyY</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.verbose" class="name">var <span class="ident">verbose</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
          <h3>Methods</h3>
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, regr=&#39;constant&#39;, corr=&#39;exponential_periodic&#39;, verbose=False, theta=array([  4.00000000e+01,   3.00000000e+01,   2.00000000e+01,
         5.00000000e-02,   1.00000000e+00,   1.00000000e+00,
         5.00000000e-01,   1.00000000e-03,   1.00000000e+01]), thetaL=array([  1.00000000e+01,   1.00000000e+00,   1.00000000e+00,
         1.00000000e-04,   1.00000000e+00,   1.00000000e-01,
         1.00000000e-01,   1.00000000e-04,   1.00000000e+00]), thetaU=array([  9.00000000e+01,   5.00000000e+01,   1.00000000e-01,
         1.00000000e+00,   1.00000000e+03,   1.00000000e+01,
         1.00000000e+00,   1.00000000e-02,   1.00000000e+02]), try_optimize=True, random_start=5, normalize=True, reNormalizeY=False, n_clusters=1, coef_latent_mapping=0.5, mapWithNoise=False, useAllNoisyY=False, model_noise=None, nugget=2.2204460492503131e-15, random_state=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.__init__', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.__init__" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regr</span><span class="o">=</span><span class="s">&#39;constant&#39;</span><span class="p">,</span> 
			 <span class="n">corr</span><span class="o">=</span><span class="s">&#39;exponential_periodic&#39;</span><span class="p">,</span>
			 <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
			 <span class="n">theta</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">40</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="o">.</span><span class="mo">05</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mo">001</span><span class="p">,</span><span class="mf">10.</span><span class="p">]),</span>
                <span class="n">thetaL</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">10.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="o">.</span><span class="mo">0001</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.0001</span><span class="p">,</span><span class="mf">1.</span><span class="p">]),</span>
                <span class="n">thetaU</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">90</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1000.</span><span class="p">,</span><span class="mf">10.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="o">.</span><span class="mo">01</span><span class="p">,</span><span class="mf">100.</span><span class="p">]),</span> 
			 <span class="n">try_optimize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
			 <span class="n">random_start</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
			 <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
			 <span class="n">reNormalizeY</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
			 <span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
			 <span class="n">coef_latent_mapping</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
			 <span class="n">mapWithNoise</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
			 <span class="n">useAllNoisyY</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
			 <span class="n">model_noise</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
			 <span class="n">nugget</span><span class="o">=</span><span class="mf">10.</span> <span class="o">*</span> <span class="n">MACHINE_EPSILON</span><span class="p">,</span>
			 <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

	<span class="bp">self</span><span class="o">.</span><span class="n">regr</span> <span class="o">=</span> <span class="n">regr</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">beta0</span> <span class="o">=</span> <span class="bp">None</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="o">=</span> <span class="n">thetaL</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="o">=</span> <span class="n">thetaU</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">reNormalizeY</span> <span class="o">=</span> <span class="n">reNormalizeY</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="n">nugget</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s">&#39;fmin_cobyla&#39;</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">random_start</span> <span class="o">=</span> <span class="n">random_start</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="o">=</span> <span class="n">try_optimize</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="bp">None</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">coef_latent_mapping</span> <span class="o">=</span> <span class="n">coef_latent_mapping</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span> <span class="o">=</span> <span class="n">mapWithNoise</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="o">=</span><span class="n">useAllNoisyY</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">corr</span> <span class="o">==</span> <span class="s">&#39;squared_exponential&#39;</span><span class="p">):</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="o">=</span> <span class="n">sq_exponential</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">0.1</span><span class="p">])</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">0.001</span><span class="p">])</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">10.</span><span class="p">])</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="o">=</span> <span class="n">exponential_periodic</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">model_noise</span> <span class="o">=</span> <span class="n">model_noise</span>
	<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_noise</span> <span class="o">==</span> <span class="s">&#39;EGN&#39;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span><span class="p">):</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="o">=</span> <span class="bp">False</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.fit">
    <p>def <span class="ident">fit</span>(</p><p>self, X, y, detailed_y_obs=None, obs_noise=None)</p>
    </div>
    

    
  
    <div class="desc"><p>The Gaussian Copula Process model fitting method.</p>
<h2>Parameters</h2>
<p><code>X</code> : double array_like<br />
        An array with shape (n_samples, n_features) with the input at which
        observations were made.  </p>
<p><code>y</code> : double array_like<br />
        An array with shape (n_samples, ) or shape (n_samples, n_targets)
        with the observations of the output to be predicted.
        Currently only 1D targets are supported.  </p>
<p><code>detailed_y_obs</code> : double list of list<br />
        A list of length n_samples where entry at position i corresponds to 
        the mutiple noisy observations (given as a list) of the input value X[i,:], 
        and whose mean is y[i].<br />
        If not None, it can be used to learn the mapping function or fit the GP,
        see parameters mapWithNoise and useAllNoisyY of the GaussianCopulaProcess class.  </p>
<p><code>obs_noise</code> : double array<br />
        An array of shape (n_samples,) corresponding to the estimated noise
        in the observed y outputs.<br />
        If not None, it can be used to model the noise with the Estimated
        Gaussian Noise method, see the model_noise parameter of the 
        GaussianCopulaProcess class.  </p>
<h2>Returns</h2>
<p><code>gcp</code> : self<br />
        A fitted Gaussian Copula Process model object awaiting data to perform
        predictions.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.fit', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.fit" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">detailed_y_obs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">obs_noise</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">	The Gaussian Copula Process model fitting method.</span>
<span class="sd">	Parameters</span>
<span class="sd">	----------</span>
<span class="sd">	`X` : double array_like  </span>
<span class="sd">		An array with shape (n_samples, n_features) with the input at which</span>
<span class="sd">		observations were made.  </span>
<span class="sd">	`y` : double array_like  </span>
<span class="sd">		An array with shape (n_samples, ) or shape (n_samples, n_targets)</span>
<span class="sd">		with the observations of the output to be predicted.</span>
<span class="sd">		Currently only 1D targets are supported.  </span>
<span class="sd">	`detailed_y_obs` : double list of list  </span>
<span class="sd">		A list of length n_samples where entry at position i corresponds to </span>
<span class="sd">		the mutiple noisy observations (given as a list) of the input value X[i,:], </span>
<span class="sd">		and whose mean is y[i].  </span>
<span class="sd">		If not None, it can be used to learn the mapping function or fit the GP,</span>
<span class="sd">		see parameters mapWithNoise and useAllNoisyY of the GaussianCopulaProcess class.  </span>
<span class="sd">	`obs_noise` : double array  </span>
<span class="sd">		An array of shape (n_samples,) corresponding to the estimated noise</span>
<span class="sd">		in the observed y outputs.  </span>
<span class="sd">		If not None, it can be used to model the noise with the Estimated</span>
<span class="sd">		Gaussian Noise method, see the model_noise parameter of the </span>
<span class="sd">		GaussianCopulaProcess class.  </span>
<span class="sd">	Returns</span>
<span class="sd">	-------</span>
<span class="sd">	`gcp` : self  </span>
<span class="sd">		A fitted Gaussian Copula Process model object awaiting data to perform</span>
<span class="sd">		predictions.  </span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="c"># Run input checks</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">()</span>
	<span class="n">X</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">array2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
	<span class="c"># Check if all CV obs are given</span>
	<span class="c"># and if so, convert this list of list to array</span>
	<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
		<span class="n">detailed_X</span><span class="p">,</span><span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="n">listOfList_toArray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">detailed_y_obs</span><span class="p">)</span>	
	<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">y_ndim_</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span>
	<span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
		<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
		<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
			<span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="n">detailed_raw_y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="k">print</span><span class="p">(</span><span class="s">&#39;Warning: code is not ready for y outputs with dimension &gt; 1&#39;</span><span class="p">)</span>
	
	<span class="c"># Reshape theta if it is one dimensional and X is not</span>
	<span class="n">x_dim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
	<span class="c">#if not(self.theta.ndim == 1):</span>
	<span class="c">#	print(&#39;Warning : theta has not the right shape&#39;)</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x_dim</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="p">)</span><span class="o">.</span><span class="n">T</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x_dim</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="p">)</span><span class="o">.</span><span class="n">T</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x_dim</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="p">)</span><span class="o">.</span><span class="n">T</span>
	<span class="c">#print(&#39;theta has new shape &#39;+str(self.theta.shape))</span>
		
	<span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>		
	<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">check_arrays</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
	<span class="c"># Check shapes of DOE &amp; observations</span>
	<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
	<span class="n">_</span><span class="p">,</span> <span class="n">n_targets</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
	<span class="c"># Run input checks</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
	<span class="c"># Normalize data or don&#39;t</span>
	<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
		<span class="n">X_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
		<span class="n">X_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
		<span class="n">X_std</span><span class="p">[</span><span class="n">X_std</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
		<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_std</span>
		<span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
		<span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
		<span class="n">raw_y_std</span><span class="p">[</span><span class="n">raw_y_std</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
		<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">raw_y_std</span>
		
		<span class="k">if</span><span class="p">(</span><span class="n">obs_noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
			<span class="n">obs_noise</span> <span class="o">=</span> <span class="n">obs_noise</span> <span class="o">/</span> <span class="n">raw_y_std</span>
		<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
			<span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">detailed_raw_y</span> <span class="o">-</span> <span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">raw_y_std</span>
			<span class="n">detailed_X</span> <span class="o">=</span> <span class="p">(</span><span class="n">detailed_X</span> <span class="o">-</span> <span class="n">X_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_std</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">X_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
		<span class="n">X_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
	
	<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>		
	<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
	<span class="c"># Set attributes</span>
	<span class="k">if</span><span class="p">(</span><span class="n">detailed_y_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="n">detailed_raw_y</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span> <span class="o">=</span> <span class="n">detailed_X</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="o">=</span> <span class="bp">None</span>			
		<span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span> <span class="o">=</span> <span class="bp">None</span>			
	
	<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="p">):</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span>
		
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">raw_y_mean</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">raw_y_std</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="o">-</span><span class="mf">500.</span><span class="p">,</span> <span class="mf">5.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)])</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span> <span class="o">=</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">X_std</span>
		<span class="c"># initialize mapping only if needed, i.e. it hasn&#39;t be done </span>
		<span class="c"># yet of if we want to optimize the GCP hyperparameters</span>
		<span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">init_mappings</span><span class="p">()</span>
	
	<span class="k">elif</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">useAllNoisyY</span> <span class="p">):</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="n">y</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">raw_y_mean</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">raw_y_std</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="o">-</span><span class="mf">500.</span><span class="p">,</span> <span class="mf">5.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)])</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span> <span class="o">=</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">X_std</span>
		<span class="c"># initialize mapping only if needed, i.e. it hasn&#39;t be done </span>
		<span class="c"># yet of if we want to optimize the GCP hyperparameters</span>
		<span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">init_mappings</span><span class="p">()</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span> <span class="o">=</span> <span class="n">y</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span> <span class="o">=</span> <span class="n">raw_y_mean</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">=</span> <span class="n">raw_y_std</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="o">-</span><span class="mf">500.</span><span class="p">,</span> <span class="mf">5.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y</span><span class="p">)])</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span> <span class="o">=</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">X_std</span>
		<span class="c"># initialize mapping only if needed, i.e. it hasn&#39;t be done </span>
		<span class="c"># yet of if we want to optimize the GCP hyperparameters</span>
		<span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">init_mappings</span><span class="p">()</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">obs_noise</span> <span class="o">=</span> <span class="n">obs_noise</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">update_copula_params</span><span class="p">()</span>
	
	<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">try_optimize</span><span class="p">:</span>
	    <span class="c"># Maximum Likelihood Estimation of the parameters</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
			<span class="k">print</span><span class="p">(</span><span class="s">&quot;Performing Maximum Likelihood Estimation of the &quot;</span>
				  <span class="s">&quot;autocorrelation parameters...&quot;</span><span class="p">)</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">,</span> <span class="n">par</span> <span class="o">=</span> \
			<span class="bp">self</span><span class="o">.</span><span class="n">_arg_max_reduced_likelihood_function</span><span class="p">()</span>
		<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">):</span>
			<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Bad parameter region. &quot;</span>
							<span class="s">&quot;Try increasing upper bound&quot;</span><span class="p">)</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="c"># Given parameters</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
			<span class="k">print</span><span class="p">(</span><span class="s">&quot;Given autocorrelation parameters. &quot;</span>
				  <span class="s">&quot;Computing Gaussian Process model parameters...&quot;</span><span class="p">)</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">,</span> <span class="n">par</span> <span class="o">=</span> \
			<span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">()</span>
		<span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function_value_</span><span class="p">):</span>
			<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Bad point. Try increasing theta0.&quot;</span><span class="p">)</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;beta&#39;</span><span class="p">]</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;gamma&#39;</span><span class="p">]</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;sigma2&#39;</span><span class="p">]</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;C&#39;</span><span class="p">]</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">Ft</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;Ft&#39;</span><span class="p">]</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;G&#39;</span><span class="p">]</span>
	<span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.get_params">
    <p>def <span class="ident">get_params</span>(</p><p>self, deep=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Get parameters for this estimator.</p>
<h2>Parameters</h2>
<p>deep: boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2>Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.get_params', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.get_params" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get parameters for this estimator.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deep: boolean, optional</span>
<span class="sd">        If True, will return the parameters for this estimator and</span>
<span class="sd">        contained subobjects that are estimators.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : mapping of string to any</span>
<span class="sd">        Parameter names mapped to their values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
        <span class="c"># We need deprecation warnings to always be on in order to</span>
        <span class="c"># catch deprecated param values.</span>
        <span class="c"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s">&quot;always&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="ne">DeprecationWarning</span><span class="p">:</span>
                <span class="c"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c"># XXX: should we rather test if instance of estimator?</span>
        <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s">&#39;get_params&#39;</span><span class="p">):</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s">&#39;__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.init_mappings">
    <p>def <span class="ident">init_mappings</span>(</p><p>self)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.init_mappings', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.init_mappings" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">init_mappings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
	<span class="c"># We assume y is one-dimensional</span>

	<span class="c"># Perform KMeans and store results</span>
	<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
		<span class="n">clustering_pending</span> <span class="o">=</span> <span class="bp">True</span>
		<span class="k">while</span><span class="p">(</span><span class="n">clustering_pending</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span><span class="mi">1</span> <span class="p">):</span>
			<span class="n">clustering_pending</span> <span class="o">=</span> <span class="bp">False</span>
			<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
			<span class="n">all_data</span> <span class="o">=</span> <span class="p">[]</span>
			<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
				<span class="n">all_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
			<span class="n">all_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">all_data</span><span class="p">)</span>
			<span class="n">windows_idx</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">all_data</span><span class="p">)</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">centroids</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
	
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
				<span class="k">print</span><span class="p">(</span><span class="s">&#39;All data shape :&#39;</span><span class="p">,</span><span class="n">all_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
				<span class="k">print</span> <span class="p">(</span><span class="s">&quot;Centroids&quot;</span><span class="p">)</span>
				<span class="k">print</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_std</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">centroids</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span><span class="o">*</span><span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span><span class="p">)</span>
			
			<span class="c"># Compute the density function for each sub-window</span>
			<span class="n">density_functions</span> <span class="o">=</span> <span class="p">[]</span>
			<span class="n">clusters_std</span> <span class="o">=</span> <span class="p">[]</span>
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
				<span class="n">detailed_windows_idx</span> <span class="o">=</span><span class="n">reshape_cluster_labels</span><span class="p">(</span><span class="n">windows_idx</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_X</span><span class="p">)</span>
			<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">):</span>
				<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
					<span class="n">cluster_points_y_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span><span class="p">[</span> <span class="n">detailed_windows_idx</span> <span class="o">==</span> <span class="n">w</span><span class="p">])[:,</span><span class="mi">0</span><span class="p">])</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="n">cluster_points_y_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[</span> <span class="n">windows_idx</span> <span class="o">==</span> <span class="n">w</span><span class="p">])[:,</span><span class="mi">0</span><span class="p">])</span>
				<span class="n">clusters_std</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span> <span class="n">windows_idx</span> <span class="o">==</span> <span class="n">w</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">)</span> <span class="c">### this is a (Xdim) array</span>
				<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
					<span class="k">print</span><span class="p">(</span><span class="s">&#39;cluster &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="s">&#39; size &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cluster_points_y_values</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
				<span class="k">if</span><span class="p">(</span><span class="n">cluster_points_y_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
					<span class="n">clustering_pending</span> <span class="o">=</span> <span class="bp">True</span>
				<span class="k">else</span><span class="p">:</span>
					<span class="n">density_functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="n">cluster_points_y_values</span><span class="p">)</span> <span class="p">)</span>
			
			<span class="k">if</span><span class="p">(</span><span class="n">clustering_pending</span><span class="p">):</span>
				<span class="k">print</span> <span class="p">(</span><span class="s">&#39;Fail to build &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#39; clusters&#39;</span><span class="p">)</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">-=</span> <span class="mi">1</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="n">density_functions</span><span class="p">)</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">density_functions</span>
				<span class="n">clusters_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">clusters_std</span><span class="p">)</span>
				<span class="n">clusters_std</span><span class="p">[</span><span class="n">clusters_std</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">clusters_std</span> <span class="o">=</span> <span class="n">clusters_std</span>
				<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
					<span class="k">print</span><span class="p">(</span><span class="s">&#39;---STD---&#39;</span><span class="p">)</span>
					<span class="k">print</span><span class="p">(</span><span class="n">clusters_std</span><span class="p">)</span>	
		<span class="k">if</span><span class="p">(</span><span class="n">clustering_pending</span><span class="p">):</span>
			<span class="c"># n_cluster == 1</span>
			<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>	
	<span class="k">else</span><span class="p">:</span>
		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapWithNoise</span><span class="p">):</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detailed_raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="p">])</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.integrate_prediction">
    <p>def <span class="ident">integrate_prediction</span>(</p><p>self, mu, sigma, x, lb, ub)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.integrate_prediction', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.integrate_prediction" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">integrate_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">):</span>
	<span class="c"># utility function for the predict method</span>
	<span class="k">def</span> <span class="nf">f_to_integrate</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
		<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
		<span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span> <span class="o">*</span> <span class="p">(</span><span class="n">u</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="p">)</span>
		<span class="k">return</span> <span class="n">temp</span>
	<span class="k">return</span><span class="p">(</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">f_to_integrate</span><span class="p">,</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">,</span><span class="n">epsrel</span> <span class="o">=</span><span class="mf">0.000000001</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping">
    <p>def <span class="ident">mapping</span>(</p><p>self, x, t, normalize=False)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">mapping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
	<span class="k">if</span><span class="p">(</span><span class="n">normalize</span><span class="p">):</span>
		<span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span>
	<span class="n">v</span> <span class="o">=</span> <span class="mf">0.</span>
	<span class="c"># if t is too big, F_est(t) will be too close to 1</span>
	<span class="c"># this is an issue as in that case norm.ppf( F_est(t) ) will return Nan</span>
	<span class="c"># so we force F_est(t) to be smaller than 0.999999998 which corresponds to</span>
	<span class="c"># norm.ppf( F_est(t) ) being smaller than 6.3</span>
	<span class="c"># Normally doing this shouldn&#39;t cause any problem. But such extrem t values can</span>
	<span class="c"># be queried by the binomial search to invert the mapping (mapping_inv)</span>
	<span class="k">if</span><span class="p">(</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="mi">2047483647</span><span class="p">):</span>
		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
			<span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
			<span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
			<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">):</span>
				<span class="c">## coefficients are :</span>
				<span class="c">#	 exp{  - sum [ (d_i /std_i) **2 ]  }</span>
				<span class="n">coefs</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_latent_mapping</span><span class="o">*</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">centroids</span><span class="p">[</span><span class="n">w</span><span class="p">])</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">clusters_std</span><span class="p">)</span><span class="o">**</span><span class="mf">2.</span> <span class="p">)</span> <span class="p">)</span>
				<span class="n">temp</span>  <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="n">w</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
				<span class="c"># if temp is too close to 1, norm.ppf(temp) == Nan</span>
				<span class="c"># if temp == 0, norm.ppf(temp) == -inf</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
				<span class="k">if</span><span class="p">(</span><span class="n">temp</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
					<span class="n">temp</span> <span class="o">=</span> <span class="mf">1e-10</span>
				<span class="n">val</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span> <span class="p">)</span> 
			
			<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coefs</span><span class="p">)</span>
			<span class="k">if</span><span class="p">(</span><span class="n">s</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
				<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">coefs</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span>
			<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">/</span> <span class="n">s</span>
			<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
			
		<span class="k">else</span><span class="p">:</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
			<span class="c"># if temp is too close to 1, norm.ppf(temp) == Nan</span>
			<span class="c"># if temp == 0, norm.ppf(temp) == -inf</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
			<span class="k">if</span><span class="p">(</span><span class="n">temp</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="mf">1e-10</span>
			<span class="n">v</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">v</span> <span class="o">=</span> <span class="mf">8.3</span>
		
	<span class="k">return</span> <span class="p">[</span><span class="n">v</span><span class="p">]</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping_derivative">
    <p>def <span class="ident">mapping_derivative</span>(</p><p>self, x, t, normalize=False)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping_derivative', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping_derivative" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">mapping_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
	<span class="c"># our mapping function is constant for t values greater than 2047483646</span>
	<span class="c"># so for such values mapping_derivate should be null</span>
	<span class="k">if</span><span class="p">(</span><span class="n">normalize</span><span class="p">):</span>
		<span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span>
	<span class="n">v</span> <span class="o">=</span> <span class="mf">0.</span>
	<span class="k">if</span><span class="p">(</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="mi">2047483646</span><span class="p">):</span>
		<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
			<span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
			<span class="n">val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
			<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">):</span>
				<span class="c">## coefficients are :</span>
				<span class="c">#	 exp{  - sum [ (d_i /std_i) **2 ]  }</span>
				<span class="n">coefs</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_latent_mapping</span><span class="o">*</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">centroids</span><span class="p">[</span><span class="n">w</span><span class="p">])</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">clusters_std</span><span class="p">)</span><span class="o">**</span><span class="mf">2.</span> <span class="p">)</span> <span class="p">)</span>
				<span class="c"># computing Psi_i (t) </span>
				<span class="n">temp</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="n">w</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span> <span class="n">temp</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">)</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
				<span class="c"># pdf( Psi_i (t))</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
				<span class="c"># d_est_i / pdf(...)</span>
				<span class="n">temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="n">w</span><span class="p">](</span><span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">temp</span>
				<span class="n">val</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span>
			<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coefs</span><span class="p">)</span>
			<span class="k">if</span><span class="p">(</span><span class="n">s</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
				<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">coefs</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span>
			<span class="n">val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">/</span> <span class="n">s</span>
			<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">temp</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">integrate_box_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low_bound</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.9999999999999999</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span> <span class="n">temp</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">)</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
			<span class="c"># pdf( Psi (t))</span>
			<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
			<span class="c"># d_est / pdf(...)</span>
			<span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">density_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">temp</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">v</span> <span class="o">=</span> <span class="mf">0.</span>
		
	<span class="k">return</span> <span class="p">(</span><span class="n">v</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span><span class="p">)</span>	
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping_inv">
    <p>def <span class="ident">mapping_inv</span>(</p><p>self, x, t)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping_inv', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.mapping_inv" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">mapping_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
	<span class="k">if</span><span class="p">(</span><span class="n">t</span><span class="o">&lt;=</span> <span class="mf">8.2</span><span class="p">):</span>
		<span class="k">def</span> <span class="nf">map</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
			<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
		<span class="n">lo</span><span class="p">,</span> <span class="n">hi</span> <span class="o">=</span> <span class="n">find_bounds</span><span class="p">(</span><span class="nb">map</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
		<span class="n">res</span> <span class="o">=</span> <span class="n">binary_search</span><span class="p">(</span><span class="nb">map</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">)</span>				
		<span class="k">return</span> <span class="p">[</span><span class="n">res</span><span class="p">]</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="k">return</span> <span class="p">[</span><span class="mi">2047483647</span><span class="p">]</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.predict">
    <p>def <span class="ident">predict</span>(</p><p>self, X, eval_MSE=False, transformY=True, returnRV=False, integratedPrediction=False, eval_confidence_bounds=False, coef_bound=1.96, batch_size=None)</p>
    </div>
    

    
  
    <div class="desc"><p>This function evaluates the Gaussian Process model at x.  </p>
<h2>Parameters</h2>
<p><code>X</code> : array_like<br />
        An array with shape (n_eval, n_features) giving the point(s) at
        which the prediction(s) should be made.  </p>
<p><code>eval_MSE</code> : boolean, optional<br />
        A boolean specifying whether the Mean Squared Error should be
        evaluated or not.<br />
        Default assumes evalMSE = False and evaluates only the BLUP (mean
        prediction).  </p>
<p><code>transformY</code> : boolean, optional<br />
        A boolean specifying if the predicted values should correspond to
        the same space as the data given to the fit method, or to the
        warped space (in which the GP is fitted).
        Default is True. Setting to False can be useful to compute the Expected
        Improvement in an optimization process.  </p>
<p><code>returnRV</code> : boolean, optional<br />
        A boolean specifying if the method should return the predicted random variables
        at x instead of a float number.<br />
        Default is False.  </p>
<p><code>integratedPrediction</code> : boolean, optional<br />
        A boolean specifying if the method should return the fully Bayesian
        prediction, ie compute the expectation given the posterior in the
        original space. If False, the returned value is the inverse value
        (by the mapping function) of the GP prediction. This is much more faster
        as the integratedPrediction needs to numerically compute the integral.
        Default is False.  </p>
<p><code>eval_confidence_bounds</code> : boolean, optional<br />
        A boolean specifying if the method should return the confidence bounds.
        Because of the non-linearity of the mapping function, this cannot be computed
        directly with the MSE, but needs to invert the mapping function.<br />
        Default is False. If True, coef_bound specifies the boundary to compute.  </p>
<p><code>coef_bound</code> : float, optional<br />
        A float specifying the confidence bounds to compute. Upper and lower
        confidence bounds are computed as the inverse of m + coef_bound*sigma
        where m and sigma are the mean and the std of the posterior in the GP
        space.<br />
        Default is 1.96 which corresponds to the 95% confidence bounds.  </p>
<p><code>batch_size</code> : integer, optional<br />
        An integer giving the maximum number of points that can be
        evaluated simultaneously (depending on the available memory).
        Default is None so that all given points are evaluated at the same
        time.  </p>
<h2>Returns</h2>
<p><code>y</code> : array_like, shape (n_samples,)<br />
        Prediction at x.</p>
<p><code>MSE</code> : array_like, optional (if eval_MSE == True)<br />
        Mean Squared Error at x.</p>
<p><code>LCB</code> : array_like, optional (if eval_confidence_bounds == True)<br />
        Lower confidence bound.</p>
<p><code>UCB</code> : array_like, optional (if eval_confidence_bounds == True)<br />
        Upper confidence bound.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.predict', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.predict" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">eval_MSE</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transformY</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">returnRV</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">integratedPrediction</span><span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">eval_confidence_bounds</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">coef_bound</span><span class="o">=</span><span class="mf">1.96</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">	This function evaluates the Gaussian Process model at x.  </span>
<span class="sd">	Parameters</span>
<span class="sd">	----------</span>
<span class="sd">	`X` : array_like  </span>
<span class="sd">		An array with shape (n_eval, n_features) giving the point(s) at</span>
<span class="sd">		which the prediction(s) should be made.  </span>
<span class="sd">	`eval_MSE` : boolean, optional  </span>
<span class="sd">		A boolean specifying whether the Mean Squared Error should be</span>
<span class="sd">		evaluated or not.  </span>
<span class="sd">		Default assumes evalMSE = False and evaluates only the BLUP (mean</span>
<span class="sd">		prediction).  </span>
<span class="sd">	`transformY` : boolean, optional  </span>
<span class="sd">		A boolean specifying if the predicted values should correspond to</span>
<span class="sd">		the same space as the data given to the fit method, or to the</span>
<span class="sd">		warped space (in which the GP is fitted).</span>
<span class="sd">		Default is True. Setting to False can be useful to compute the Expected</span>
<span class="sd">		Improvement in an optimization process.  </span>
<span class="sd">	`returnRV` : boolean, optional  </span>
<span class="sd">		A boolean specifying if the method should return the predicted random variables</span>
<span class="sd">		at x instead of a float number.  </span>
<span class="sd">		Default is False.  </span>
<span class="sd">	`integratedPrediction` : boolean, optional  </span>
<span class="sd">		A boolean specifying if the method should return the fully Bayesian</span>
<span class="sd">		prediction, ie compute the expectation given the posterior in the</span>
<span class="sd">		original space. If False, the returned value is the inverse value</span>
<span class="sd">		(by the mapping function) of the GP prediction. This is much more faster</span>
<span class="sd">		as the integratedPrediction needs to numerically compute the integral.</span>
<span class="sd">		Default is False.  </span>
<span class="sd">	`eval_confidence_bounds` : boolean, optional  </span>
<span class="sd">		A boolean specifying if the method should return the confidence bounds.</span>
<span class="sd">		Because of the non-linearity of the mapping function, this cannot be computed</span>
<span class="sd">		directly with the MSE, but needs to invert the mapping function.  </span>
<span class="sd">		Default is False. If True, coef_bound specifies the boundary to compute.  </span>
<span class="sd">	`coef_bound` : float, optional  </span>
<span class="sd">		A float specifying the confidence bounds to compute. Upper and lower</span>
<span class="sd">		confidence bounds are computed as the inverse of m + coef_bound*sigma</span>
<span class="sd">		where m and sigma are the mean and the std of the posterior in the GP</span>
<span class="sd">		space.  </span>
<span class="sd">		Default is 1.96 which corresponds to the 95% confidence bounds.  </span>
<span class="sd">	`batch_size` : integer, optional  </span>
<span class="sd">		An integer giving the maximum number of points that can be</span>
<span class="sd">		evaluated simultaneously (depending on the available memory).</span>
<span class="sd">		Default is None so that all given points are evaluated at the same</span>
<span class="sd">		time.  </span>
<span class="sd">	Returns</span>
<span class="sd">	-------</span>
<span class="sd">	`y` : array_like, shape (n_samples,)  </span>
<span class="sd">		Prediction at x.</span>
<span class="sd">	`MSE` : array_like, optional (if eval_MSE == True)  </span>
<span class="sd">		Mean Squared Error at x.</span>
<span class="sd">	`LCB` : array_like, optional (if eval_confidence_bounds == True)  </span>
<span class="sd">		Lower confidence bound.</span>
<span class="sd">	`UCB` : array_like, optional (if eval_confidence_bounds == True)  </span>
<span class="sd">		Upper confidence bound.</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="c"># Check input shapes</span>
	<span class="n">X</span> <span class="o">=</span> <span class="n">sk_utils</span><span class="o">.</span><span class="n">array2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
	<span class="n">n_eval</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
	<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span>
	<span class="n">n_samples_y</span><span class="p">,</span> <span class="n">n_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span>
	<span class="k">if</span><span class="p">(</span><span class="n">n_targets</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
		<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&#39;More than one target in the Y outputs. </span><span class="se">\</span>
<span class="s">						  Currently only 1D outputs are handled&#39;</span><span class="p">)</span>
	<span class="c"># Run input checks</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">n_features</span><span class="p">:</span>
		<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s">&quot;The number of features in X (X.shape[1] = </span><span class="si">%d</span><span class="s">) &quot;</span>
						  <span class="s">&quot;should match the number of features used &quot;</span>
						  <span class="s">&quot;for fit() &quot;</span>
						  <span class="s">&quot;which is </span><span class="si">%d</span><span class="s">.&quot;</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_features</span><span class="p">))</span>
	<span class="c"># Normalize input</span>
	<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
		<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span>
		
	<span class="c"># Initialize output</span>
	<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_eval</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">eval_MSE</span><span class="p">:</span>
		<span class="n">MSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_eval</span><span class="p">)</span>
	<span class="c"># Get pairwise componentwise L1-distances to the input training set</span>
	<span class="n">dx</span> <span class="o">=</span> <span class="n">manhattan_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">sum_over_features</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
	<span class="c"># Get regression function and correlation</span>
	<span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
	<span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">dx</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
	<span class="c"># Scaled predictor</span>
	<span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>
	<span class="c"># Predictor</span>
	<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">*</span> <span class="n">y_</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span>
	<span class="c"># transform the warped y, modeled as a Gaussian, to the real y</span>
	<span class="n">size</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
	<span class="n">warped_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
	
	<span class="k">if</span><span class="p">(</span><span class="n">transformY</span><span class="p">):</span>
		<span class="k">if</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">8.2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)])</span> <span class="o">&gt;</span><span class="mi">0</span><span class="p">):</span>
			<span class="k">print</span><span class="p">(</span><span class="s">&#39;Warning : mapping_inversion failed&#39;</span><span class="p">)</span>
		<span class="n">real_y</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_inv</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
		<span class="n">real_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">real_y</span><span class="p">)</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span>
		<span class="n">y</span> <span class="o">=</span> <span class="n">real_y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span>
	
	<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_ndim_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
		<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
		<span class="n">warped_y</span> <span class="o">=</span> <span class="n">warped_y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
	<span class="c"># Mean Squared Error</span>
	<span class="k">if</span> <span class="n">eval_MSE</span><span class="p">:</span>
		<span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span>
		<span class="k">if</span> <span class="n">C</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
			<span class="c"># Light storage mode (need to recompute C, F, Ft and G)</span>
			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
				<span class="k">print</span><span class="p">(</span><span class="s">&quot;This GaussianProcess used &#39;light&#39; storage mode &quot;</span>
					  <span class="s">&quot;at instantiation. Need to recompute &quot;</span>
					  <span class="s">&quot;autocorrelation matrix...&quot;</span><span class="p">)</span>
			<span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span> <span class="o">=</span> \
				<span class="bp">self</span><span class="o">.</span><span class="n">reduced_likelihood_function</span><span class="p">()</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;C&#39;</span><span class="p">]</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">Ft</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;Ft&#39;</span><span class="p">]</span>
			<span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="s">&#39;G&#39;</span><span class="p">]</span>
		<span class="n">rt</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta0</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
			<span class="c"># Universal Kriging</span>
			<span class="n">u</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
										<span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Ft</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rt</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="c"># Ordinary Kriging</span>
			<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_targets</span><span class="p">,</span> <span class="n">n_eval</span><span class="p">))</span>
		<span class="n">MSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_targets</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
					 <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="p">(</span><span class="n">rt</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
					  <span class="o">+</span> <span class="p">(</span><span class="n">u</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:])</span>
		<span class="n">MSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">MSE</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_targets</span><span class="p">)</span>
		<span class="c"># Mean Squared Error might be slightly negative depending on</span>
		<span class="c"># machine precision: force to zero!</span>
		<span class="n">MSE</span><span class="p">[</span><span class="n">MSE</span> <span class="o">&lt;</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_ndim_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
			<span class="n">MSE</span> <span class="o">=</span> <span class="n">MSE</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
			<span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">MSE</span><span class="p">)</span>
			<span class="k">if</span><span class="p">(</span><span class="n">returnRV</span><span class="p">):</span>
				<span class="k">return</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">predicted_RV</span><span class="p">([</span><span class="n">warped_y</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
			<span class="k">else</span><span class="p">:</span>
				<span class="k">if</span><span class="p">(</span><span class="n">eval_confidence_bounds</span><span class="p">):</span>
					<span class="k">if</span> <span class="ow">not</span><span class="p">(</span><span class="n">transformY</span><span class="p">):</span>
						<span class="k">print</span><span class="p">(</span><span class="s">&#39;Warning, transformY set to False but trying to evaluate conf bounds&#39;</span><span class="p">)</span>
					<span class="n">warped_y_with_boundL</span> <span class="o">=</span> <span class="n">warped_y</span> <span class="o">-</span> <span class="n">coef_bound</span> <span class="o">*</span> <span class="n">sigma</span>
					<span class="n">warped_y_with_boundU</span> <span class="o">=</span> <span class="n">warped_y</span> <span class="o">+</span> <span class="n">coef_bound</span> <span class="o">*</span> <span class="n">sigma</span>
					<span class="n">pred_with_boundL</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_inv</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">warped_y_with_boundL</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="p">]</span> <span class="p">)</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span>
					<span class="n">pred_with_boundU</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_inv</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">warped_y_with_boundU</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span> <span class="p">)</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_mean</span>
					
					<span class="k">if</span><span class="p">(</span><span class="n">integratedPrediction</span><span class="p">):</span>
						<span class="n">lb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span> <span class="o">-</span> <span class="mf">3.</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span><span class="p">)</span>
						<span class="n">ub</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span> <span class="o">+</span> <span class="mf">3.</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_max</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y_min</span><span class="p">)</span>
						<span class="k">print</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">)</span>
						<span class="n">integrated_real_y</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">integrate_prediction</span><span class="p">([</span><span class="n">warped_y</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
						<span class="n">integrated_real_y</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">integrated_real_y</span><span class="p">)</span>
						<span class="k">print</span><span class="p">(</span><span class="s">&#39;Integrated prediction&#39;</span><span class="p">)</span>
						<span class="k">return</span> <span class="n">integrated_real_y</span><span class="p">,</span><span class="n">MSE</span><span class="p">,</span><span class="n">pred_with_boundL</span><span class="p">,</span><span class="n">pred_with_boundU</span>
					<span class="k">else</span><span class="p">:</span>
						<span class="k">return</span> <span class="n">y</span><span class="p">,</span><span class="n">MSE</span><span class="p">,</span><span class="n">pred_with_boundL</span><span class="p">,</span><span class="n">pred_with_boundU</span>
					
				<span class="k">else</span><span class="p">:</span>
					<span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">MSE</span>
		
		<span class="k">else</span><span class="p">:</span>
			<span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">MSE</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="k">return</span> <span class="n">y</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.predicted_RV">
    <p>def <span class="ident">predicted_RV</span>(</p><p>self, mu, sigma, x)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.predicted_RV', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.predicted_RV" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">predicted_RV</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
	<span class="c"># utility function for the predict method</span>
	<span class="k">def</span> <span class="nf">f_to_integrate</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
		<span class="n">temp</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
		<span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span> <span class="o">*</span> <span class="p">(</span><span class="n">u</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="p">)</span>
		<span class="k">return</span> <span class="n">temp</span>
	<span class="k">return</span> <span class="n">f_to_integrate</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.reduced_likelihood_function">
    <p>def <span class="ident">reduced_likelihood_function</span>(</p><p>self, theta=None)</p>
    </div>
    

    
  
    <div class="desc"><p>This function determines the BLUP parameters and evaluates the reduced
likelihood function for the given autocorrelation parameters theta.</p>
<p>Maximizing this function wrt the autocorrelation parameters theta is
equivalent to maximizing the likelihood of the assumed joint Gaussian
distribution of the observations y evaluated onto the design of
experiments X.</p>
<h2>Parameters</h2>
<p><code>theta</code> : array_like, optional
        An array containing the autocorrelation parameters at which the
        Gaussian Process model parameters should be determined.
        Default uses the built-in autocorrelation parameters
        (ie <code>theta = self.theta_</code>).</p>
<h2>Returns</h2>
<p><code>reduced_likelihood_function_value</code> : double
        The value of the reduced likelihood function associated to the
        given autocorrelation parameters theta.</p>
<p><code>par</code> : dict
        A dictionary containing the requested Gaussian Process model
        parameters:</p>
<div class="codehilite"><pre>            sigma2
                            Gaussian Process variance.
            beta
                            Generalized least-squares regression weights for
                            Universal Kriging or given beta0 for Ordinary
                            Kriging.
            gamma
                            Gaussian Process weights.
            C
                            Cholesky decomposition of the correlation matrix [R].
            Ft
                            Solution of the linear equation system : [R] x Ft = F
            G
                            QR decomposition of the matrix Ft.
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.reduced_likelihood_function', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.reduced_likelihood_function" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">reduced_likelihood_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">	This function determines the BLUP parameters and evaluates the reduced</span>
<span class="sd">	likelihood function for the given autocorrelation parameters theta.</span>
<span class="sd">	Maximizing this function wrt the autocorrelation parameters theta is</span>
<span class="sd">	equivalent to maximizing the likelihood of the assumed joint Gaussian</span>
<span class="sd">	distribution of the observations y evaluated onto the design of</span>
<span class="sd">	experiments X.</span>
<span class="sd">	Parameters</span>
<span class="sd">	----------</span>
<span class="sd">	`theta` : array_like, optional</span>
<span class="sd">		An array containing the autocorrelation parameters at which the</span>
<span class="sd">		Gaussian Process model parameters should be determined.</span>
<span class="sd">		Default uses the built-in autocorrelation parameters</span>
<span class="sd">		(ie ``theta = self.theta_``).</span>
<span class="sd">	Returns</span>
<span class="sd">	-------</span>
<span class="sd">	`reduced_likelihood_function_value` : double</span>
<span class="sd">		The value of the reduced likelihood function associated to the</span>
<span class="sd">		given autocorrelation parameters theta.</span>
<span class="sd">	`par` : dict</span>
<span class="sd">		A dictionary containing the requested Gaussian Process model</span>
<span class="sd">		parameters:</span>
<span class="sd">			sigma2</span>
<span class="sd">					Gaussian Process variance.</span>
<span class="sd">			beta</span>
<span class="sd">					Generalized least-squares regression weights for</span>
<span class="sd">					Universal Kriging or given beta0 for Ordinary</span>
<span class="sd">					Kriging.</span>
<span class="sd">			gamma</span>
<span class="sd">					Gaussian Process weights.</span>
<span class="sd">			C</span>
<span class="sd">					Cholesky decomposition of the correlation matrix [R].</span>
<span class="sd">			Ft</span>
<span class="sd">					Solution of the linear equation system : [R] x Ft = F</span>
<span class="sd">			G</span>
<span class="sd">					QR decomposition of the matrix Ft.</span>
<span class="sd">	&quot;&quot;&quot;</span>
	
	<span class="k">if</span> <span class="n">theta</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
		<span class="c"># Use built-in autocorrelation parameters</span>
		<span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span>
	<span class="c"># Initialize output</span>
	<span class="n">reduced_likelihood_function_value</span> <span class="o">=</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
	<span class="n">par</span> <span class="o">=</span> <span class="p">{}</span>
	<span class="c"># Retrieve data</span>
	<span class="n">n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
	<span class="n">D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span>
	<span class="n">ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ij</span>
	<span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span>
	<span class="k">if</span> <span class="n">D</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
		<span class="c"># Light storage mode (need to recompute D, ij and F)</span>
		<span class="n">D</span><span class="p">,</span> <span class="n">ij</span> <span class="o">=</span> <span class="n">l1_cross_distances</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
		<span class="c">#if (np.min(np.sum(D, axis=1)) == 0.):</span>
		<span class="c">#	raise Exception(&quot;Multiple X are not allowed&quot;)</span>
		<span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
	<span class="c"># Set up R</span>
	<span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
	<span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span><span class="p">)</span>
	<span class="n">R</span><span class="p">[</span><span class="n">ij</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ij</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">r</span>
	<span class="n">R</span><span class="p">[</span><span class="n">ij</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ij</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">r</span>
	<span class="c"># Cholesky decomposition of R</span>
	<span class="k">try</span><span class="p">:</span>
		<span class="n">C</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
	<span class="k">except</span> <span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
		<span class="k">return</span> <span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span>
	<span class="c"># Get generalized least squares solution</span>
	<span class="n">Ft</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
	<span class="k">try</span><span class="p">:</span>
		<span class="n">Q</span><span class="p">,</span> <span class="n">G</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
	<span class="k">except</span><span class="p">:</span>
		<span class="c">#/usr/lib/python2.6/dist-packages/scipy/linalg/decomp.py:1177:</span>
		<span class="c"># DeprecationWarning: qr econ argument will be removed after scipy</span>
		<span class="c"># 0.7. The economy transform will then be available through the</span>
		<span class="c"># mode=&#39;economic&#39; argument.</span>
		<span class="n">Q</span><span class="p">,</span> <span class="n">G</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;economic&#39;</span><span class="p">)</span>
		<span class="k">pass</span>
	<span class="n">sv</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
	<span class="n">rcondG</span> <span class="o">=</span> <span class="n">sv</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">sv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
	<span class="k">if</span> <span class="n">rcondG</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
		<span class="c"># Check F</span>
		<span class="n">sv</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
		<span class="n">condF</span> <span class="o">=</span> <span class="n">sv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">sv</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
		<span class="k">if</span> <span class="n">condF</span> <span class="o">&gt;</span> <span class="mf">1e15</span><span class="p">:</span>
			<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;F is too ill conditioned. Poor combination &quot;</span>
							<span class="s">&quot;of regression model and observations.&quot;</span><span class="p">)</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="c"># Ft is too ill conditioned, get out (try different theta)</span>
			<span class="k">return</span> <span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span>
	<span class="n">Yt</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
	<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta0</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
		<span class="c"># Universal Kriging</span>
		<span class="n">beta</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Yt</span><span class="p">))</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="c"># Ordinary Kriging</span>
		<span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta0</span><span class="p">)</span>
	<span class="n">rho</span> <span class="o">=</span> <span class="n">Yt</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
	<span class="n">sigma2</span> <span class="o">=</span> <span class="p">(</span><span class="n">rho</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_samples</span>
	<span class="c"># The determinant of R is equal to the squared product of the diagonal</span>
	<span class="c"># elements of its Cholesky decomposition C</span>
	<span class="n">detR</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">C</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">/</span> <span class="n">n_samples</span><span class="p">))</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>
	<span class="c"># Compute/Organize output</span>
	<span class="n">reduced_likelihood_function_value</span> <span class="o">=</span> <span class="o">-</span> <span class="n">sigma2</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="n">detR</span>
	<span class="n">par</span><span class="p">[</span><span class="s">&#39;sigma2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">**</span> <span class="mf">2.</span>
	<span class="n">par</span><span class="p">[</span><span class="s">&#39;beta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span>
	<span class="n">par</span><span class="p">[</span><span class="s">&#39;gamma&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rho</span><span class="p">)</span>
	<span class="n">par</span><span class="p">[</span><span class="s">&#39;C&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">C</span>
	<span class="n">par</span><span class="p">[</span><span class="s">&#39;Ft&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Ft</span>
	<span class="n">par</span><span class="p">[</span><span class="s">&#39;G&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">G</span>
	<span class="k">return</span> <span class="n">reduced_likelihood_function_value</span><span class="p">,</span> <span class="n">par</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.score">
    <p>def <span class="ident">score</span>(</p><p>self, X, y, sample_weight=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the regression
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the residual
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
Best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2>Parameters</h2>
<p>X : array-like, shape = (n_samples, n_features)
    Test samples.</p>
<p>y : array-like, shape = (n_samples) or (n_samples, n_outputs)
    True values for X.</p>
<p>sample_weight : array-like, shape = [n_samples], optional
    Sample weights.</p>
<h2>Returns</h2>
<p>score : float
    R^2 of self.predict(X) wrt. y.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.score', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.score" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the coefficient of determination R^2 of the prediction.</span>
<span class="sd">    The coefficient R^2 is defined as (1 - u/v), where u is the regression</span>
<span class="sd">    sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual</span>
<span class="sd">    sum of squares ((y_true - y_true.mean()) ** 2).sum().</span>
<span class="sd">    Best possible score is 1.0 and it can be negative (because the</span>
<span class="sd">    model can be arbitrarily worse). A constant model that always</span>
<span class="sd">    predicts the expected value of y, disregarding the input features,</span>
<span class="sd">    would get a R^2 score of 0.0.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape = (n_samples, n_features)</span>
<span class="sd">        Test samples.</span>
<span class="sd">    y : array-like, shape = (n_samples) or (n_samples, n_outputs)</span>
<span class="sd">        True values for X.</span>
<span class="sd">    sample_weight : array-like, shape = [n_samples], optional</span>
<span class="sd">        Sample weights.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        R^2 of self.predict(X) wrt. y.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
    <span class="k">return</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.set_params">
    <p>def <span class="ident">set_params</span>(</p><p>self, **params)</p>
    </div>
    

    
  
    <div class="desc"><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The former have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2>Returns</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.set_params', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.set_params" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set the parameters of this estimator.</span>
<span class="sd">    The method works on simple estimators as well as on nested objects</span>
<span class="sd">    (such as pipelines). The former have parameters of the form</span>
<span class="sd">    ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s possible to update each</span>
<span class="sd">    component of a nested object.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
        <span class="c"># Simple optimisation to gain speed (inspect is slow)</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="n">split</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;__&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">split</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c"># nested objects case</span>
            <span class="n">name</span><span class="p">,</span> <span class="n">sub_name</span> <span class="o">=</span> <span class="n">split</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&#39;Invalid parameter </span><span class="si">%s</span><span class="s"> for estimator </span><span class="si">%s</span><span class="s">. &#39;</span> 
                                 <span class="s">&#39;Check the list of available parameters &#39;</span>
                                 <span class="s">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>
            <span class="n">sub_object</span> <span class="o">=</span> <span class="n">valid_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
            <span class="n">sub_object</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="n">sub_name</span><span class="p">:</span> <span class="n">value</span><span class="p">})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># simple objects case</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&#39;Invalid parameter </span><span class="si">%s</span><span class="s"> for estimator </span><span class="si">%s</span><span class="s">. &#39;</span>
                                 <span class="s">&#39;Check the list of available parameters &#39;</span>
                                 <span class="s">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">))</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="gcp_hpo.gcp.gcp.GaussianCopulaProcess.update_copula_params">
    <p>def <span class="ident">update_copula_params</span>(</p><p>self)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.update_copula_params', this);">Show source &equiv;</a></p>
  <div id="source-gcp_hpo.gcp.gcp.GaussianCopulaProcess.update_copula_params" class="source">
    <div class="codehilite"><pre><span class="k">def</span> <span class="nf">update_copula_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
	<span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
	<span class="n">y</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
	<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
	
	<span class="c"># Normalize data</span>
	<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reNormalizeY</span><span class="p">):</span>
		<span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
		<span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
		<span class="n">y_std</span><span class="p">[</span><span class="n">y_std</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">y_mean</span> <span class="o">=</span> <span class="mf">0.</span>
		<span class="n">y_std</span> <span class="o">=</span> <span class="mf">1.</span>
	<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_std</span>
	<span class="k">if</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">obs_noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_noise</span> <span class="o">==</span> <span class="s">&#39;EGN&#39;</span> <span class="p">):</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">*</span><span class="p">(</span> <span class="p">(</span> <span class="mf">10.</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs_noise</span> <span class="p">)</span> <span class="o">**</span> <span class="mf">2.</span> <span class="p">)</span>
	<span class="c"># Calculate matrix of distances D between samples</span>
	<span class="n">D</span><span class="p">,</span> <span class="n">ij</span> <span class="o">=</span> <span class="n">l1_cross_distances</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
	<span class="c">#if (np.min(np.sum(D, axis=1)) == 0.):</span>
	<span class="c">#	raise Exception(&quot;Multiple input features cannot have the same&quot;</span>
	<span class="c">#					&quot; target value.&quot;)</span>
	<span class="n">n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
	<span class="c"># Regression matrix and parameters</span>
	<span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
	<span class="n">n_samples_F</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
	<span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
		<span class="n">p</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
	<span class="k">if</span> <span class="n">n_samples_F</span> <span class="o">!=</span> <span class="n">n_samples</span><span class="p">:</span>
		<span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Number of rows in F and X do not match. Most &quot;</span>
						<span class="s">&quot;likely something is going wrong with the &quot;</span>
						<span class="s">&quot;regression model.&quot;</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="n">n_samples_F</span><span class="p">:</span>
		<span class="k">raise</span> <span class="ne">Exception</span><span class="p">((</span><span class="s">&quot;Ordinary least squares problem is undetermined &quot;</span>
						 <span class="s">&quot;n_samples=</span><span class="si">%d</span><span class="s"> must be greater than the &quot;</span>
						 <span class="s">&quot;regression model size p=</span><span class="si">%d</span><span class="s">.&quot;</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">D</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">ij</span> <span class="o">=</span> <span class="n">ij</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">F</span> <span class="o">=</span> <span class="n">F</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
	<span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">=</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span>
</pre></div>

  </div>
</div>

  </div>
  
      </div>
      </div>

  </section>

    </article>
  <div class="clear"> </div>
  <footer id="footer">
    <p>
      Documentation generated by
      <a href="https://github.com/BurntSushi/pdoc">pdoc 0.3.1</a>
    </p>

    <p>pdoc is in the public domain with the
      <a href="http://unlicense.org">UNLICENSE</a></p>

    <p>Design by <a href="http://nadh.in">Kailash Nadh</a></p>
  </footer>
</div>
</body>
</html>
